{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from models.ranked_transformer import Moonshot\n",
    "from models.chemformer.tokeniser import MolEncTokeniser\n",
    "from pathlib import Path\n",
    "from models.chemformer.utils import REGEX, DEFAULT_MAX_SEQ_LEN\n",
    "from datasets.generic_index_dataset import GenericIndexedModule\n",
    "\n",
    "from datasets.dataset_utils import pad, tokenise_and_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./tempdata/epoch=76-step=264264.ckpt\"\n",
    "vocab_path = \"tempdata/chemformer/bart_vocab.txt\"\n",
    "chem_token_start = 272"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokeniser = MolEncTokeniser.from_vocab_file(\n",
    "  vocab_path, REGEX, chem_token_start\n",
    ")\n",
    "direct = Path(\"tempdata/SMILES_dataset\")\n",
    "features = [\"HSQC\", \"SMILES\"]\n",
    "def tam(a):\n",
    "  return tokenise_and_mask(a, tokeniser)\n",
    "feature_handlers = [pad, tam]\n",
    "gim = GenericIndexedModule(direct, features, feature_handlers, len_override = 5)\n",
    "gim.setup(\"fit\")\n",
    "val_dl = gim.val_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = torch.load(\"tempdata/chemformer/model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pad_token_idx': 0,\n",
       " 'vocab_size': 523,\n",
       " 'd_model': 512,\n",
       " 'num_layers': 6,\n",
       " 'num_heads': 8,\n",
       " 'd_feedforward': 2048,\n",
       " 'lr': 1.0,\n",
       " 'weight_decay': 0.0,\n",
       " 'activation': 'gelu',\n",
       " 'num_steps': 1933600,\n",
       " 'max_seq_len': 512,\n",
       " 'dropout': 0.1,\n",
       " 'schedule': 'transformer',\n",
       " 'warm_up_steps': 8000,\n",
       " 'batch_size': 128,\n",
       " 'acc_batches': 1,\n",
       " 'mask_prob': 0.1,\n",
       " 'epochs': 10,\n",
       " 'clip_grad': 1.0,\n",
       " 'train_tokens': 'None',\n",
       " 'num_buckets': 12,\n",
       " 'limit_val_batches': 1.0,\n",
       " 'augment': True,\n",
       " 'task': 'mask_aug'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj[\"hyper_parameters\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "  'pad_token_idx': 0,\n",
    "  'vocab_size': 523,\n",
    "  'd_model': 512,\n",
    "  'num_layers': 6,\n",
    "  'num_heads': 8,\n",
    "  'd_feedforward': 2048,\n",
    "  'lr': 1.0,\n",
    "  'weight_decay': 0.0,\n",
    "  'activation': 'gelu',\n",
    "  'num_steps': 1933600,\n",
    "  'max_seq_len': 512,\n",
    "  'dropout': 0.1,\n",
    "  'schedule': 'transformer',\n",
    "  'warm_up_steps': 8000,\n",
    "  'batch_size': 128,\n",
    "  'acc_batches': 1,\n",
    "  'mask_prob': 0.1,\n",
    "  'epochs': 10,\n",
    "  'clip_grad': 1.0,\n",
    "  'train_tokens': 'None',\n",
    "  'num_buckets': 12,\n",
    "  'limit_val_batches': 1.0,\n",
    "  'augment': True,\n",
    "  'task': 'mask_aug',\n",
    "  'module_only': True,\n",
    "  'dim_model': 512,\n",
    "  'dim_coords': [224, 224, 64],\n",
    "  'coord_enc': 'sce',\n",
    "  'wavelength_bounds': [[0.01, 250], [0.01, 250]],\n",
    "  'gce_resolution': 0.1,\n",
    "  'heads': 4,\n",
    "  'layers': 4,\n",
    "  'lr': 1.0e-3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/pytorch_lightning/utilities/migration/utils.py:49: PossibleUserWarning: The loaded checkpoint was produced with Lightning v2.0.2, which is newer than your current Lightning version: v2.0.1.post0\n",
      "  rank_zero_warn(\n",
      "Initialized SignCoordinateEncoder[512] with dims [224, 224, 64] and 2 positional encoders. 64 bits are reserved for encoding the final bit\n"
     ]
    }
   ],
   "source": [
    "model = Moonshot.load_from_checkpoint(path, strict=False, **args).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (hsqc, collated_smiles) in val_dl:\n",
    "  hsqc, collated_smiles = hsqc.cuda(), {k: (v.cuda() if k != \"raw_smiles\" else v) for k,v in collated_smiles.items()}\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin_tok_idx=2 pad_tok_idx=0 end_tok_idx=3\n",
      "torch.Size([51, 2])\n"
     ]
    }
   ],
   "source": [
    "begin_tok, pad_tok, end_tok = tokeniser.begin_token, tokeniser.pad_token, tokeniser.end_token\n",
    "begin_tok_idx, pad_tok_idx, end_tok_idx = tokeniser.vocab[begin_tok], tokeniser.vocab[pad_tok], tokeniser.vocab[end_tok]\n",
    "print(f\"{begin_tok_idx=} {pad_tok_idx=} {end_tok_idx=}\")\n",
    "\n",
    "seq_len = 50\n",
    "b_s = 8\n",
    "\n",
    "token_ids = [begin_tok_idx] + ([pad_tok_idx] * (seq_len - 1))\n",
    "token_ids = torch.tensor(token_ids)[None, :].tile((b_s, 1)).cuda()\n",
    "decoder_pad_mask = torch.zeros((b_s, seq_len)).cuda()\n",
    "print(token_ids.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/transformer.py:276: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. (Triggered internally at /opt/conda/conda-bld/pytorch_1670525552843/work/aten/src/ATen/NestedTensorImpl.cpp:175.)\n",
      "  output = torch._nested_tensor_from_mask(output, src_key_padding_mask.logical_not(), mask_check=False)\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "  for i in range(1, seq_len):\n",
    "    decoder_inputs = token_ids[:,:i]\n",
    "    decoder_mask = token_ids[:,:i]\n",
    "    my_collated_smiles = {\n",
    "      \"decoder_inputs\": decoder_inputs,\n",
    "      \"decoder_mask\": decoder_mask,\n",
    "    }\n",
    "    output = model.forward((hsqc, collated_smiles))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
