{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "torch.set_printoptions(precision=10)\n",
    "\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from models.ranked_transformer import HsqcRankedTransformer\n",
    "\n",
    "from models.optional_input_ranked_transformer import OptionalInputRankedTransformer\n",
    "from datasets.optional_2d_folder_dataset import OptionalInputDataModule\n",
    "import yaml\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "torch.set_float32_matmul_precision('medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.dataset_utils import  fp_loader_configer\n",
    "fp_loader_configer.select_version(\"MFP_Specific_Radius\")\n",
    "fp_loader = fp_loader_configer.fp_loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we compare models' performance over 7 kinds of inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish entropy list\n"
     ]
    }
   ],
   "source": [
    "# load model \n",
    "\n",
    "model_path = Path(\"/root/MorganFP_prediction/reproduce_previous_works/fix_combining_dataset_load_mfp_bug/train_on_all_data_possible/only_c_trial_1\")\n",
    "# Path(\"/root/MorganFP_prediction/reproduce_previous_works/weird_H_and_tautomer_cleaned/train_on_all_data_possible/only_hsqc_trial_1/\")\n",
    "\n",
    "checkpoint_path = model_path / \"checkpoints/epoch=19-step=32320.ckpt\"\n",
    "# model_path / \"checkpoints/epoch=21-step=37708.ckpt\"\n",
    "\n",
    "\n",
    "hyperpaerameters_path = model_path / \"hparams.yaml\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with open(hyperpaerameters_path, 'r') as file:\n",
    "    hparams = yaml.safe_load(file)\n",
    "    \n",
    "FP_building_type = hparams['FP_building_type'].split(\"_\")[-1]\n",
    "only_2d = not hparams['use_oneD_NMR_no_solvent']\n",
    "fp_loader.setup(only_2d=only_2d,FP_building_type=FP_building_type)\n",
    "fp_loader.set_max_radius(int(hparams['FP_choice'].split(\"_\")[-1][1:]), only_2d=only_2d)\n",
    "\n",
    "\n",
    "del hparams['checkpoint_path'] # prevent double defition of checkpoint_path\n",
    "hparams['use_peak_values'] = False\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialized SignCoordinateEncoder[384] with dims [180, 180, 24] and 2 positional encoders. 24 bits are reserved for encoding the final bit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HsqcRankedTransformer saving args\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = HsqcRankedTransformer.load_from_checkpoint(checkpoint_path, **hparams)\n",
    "model.change_ranker_for_testing()\n",
    "# model.change_ranker_for_testing(test_ranking_set_path = \"/workspace/ranking_sets_cleaned_by_inchi/SMILES_R0_to_R4_reduced_FP_ranking_sets_only_all_info_molecules/test/rankingset.pt\")\n",
    "model=model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule = OptionalInputDataModule(dir=\"/workspace/SMILES_dataset\", FP_choice=hparams[\"FP_choice\"], input_src=[\"HSQC\", \"oneD_NMR\"], batch_size=hparams['bs'], parser_args=hparams)\n",
    "\n",
    "datamodule.setup(\"test\")\n",
    "loader_all_inputs, loader_HSQC_H_NMR, loader_HSQC_C_NMR, loader_only_hsqc, loader_only_1d, loader_only_H_NMR, loader_only_C_NMR = \\\n",
    "    datamodule.test_dataloader()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer()\n",
    "metric_to_focus = [\n",
    "    'rank_1',\n",
    "    'rank_5',\n",
    "    \"mean_rank\",\n",
    "    'cos',\n",
    "    'f1'    \n",
    "]\n",
    "def show_model_performance(model, out_file =\"temp_model_show.txt\"):\n",
    "    # loaders = [loader_all_inputs, loader_HSQC_H_NMR, loader_HSQC_C_NMR, loader_only_hsqc, loader_only_1d, loader_only_H_NMR, loader_only_C_NMR]\n",
    "    # names = [\"all_inputs\", \"HSQC_H_NMR\", \"HSQC_C_NMR\", \"only_hsqc\", \"only_1d\", \"only_H_NMR\", \"only_C_NMR\"]\n",
    "    loaders = [ loader_only_C_NMR]\n",
    "\n",
    "    names = [ \"only_C_NMR\"]\n",
    "    # names = [\"only_hsqc\"]\n",
    "    with open(out_file, \"w\") as file:\n",
    "        for loader, name in zip(loaders, names):\n",
    "            result =  trainer.test(model, dataloaders=loader)\n",
    "            file.write(f\"\\n{name:10}: \")\n",
    "            for m in metric_to_focus:\n",
    "                file.write(f\"{m}: {result[0]['test/mean_'+m]:.4f}, \")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/root/MorganFP_prediction/reproduce_previous_works/Spectre/datasets/optional_2d_folder_dataset.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  c_tensor, h_tensor = torch.load(f\"{self.dir}/oneD_NMR/{self.files[i]}\")   # both\n",
      "/root/MorganFP_prediction/reproduce_previous_works/Spectre/datasets/optional_2d_folder_dataset.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  c_tensor, h_tensor = torch.load(f\"{self.dir}/oneD_NMR/{self.files[i]}\")   # both\n",
      "/root/MorganFP_prediction/reproduce_previous_works/Spectre/datasets/optional_2d_folder_dataset.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  c_tensor, h_tensor = torch.load(f\"{self.dir}/oneD_NMR/{self.files[i]}\")   # both\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77b00446fe8b4d5fa1c479fca2b19d9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/MorganFP_prediction/reproduce_previous_works/Spectre/datasets/optional_2d_folder_dataset.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  c_tensor, h_tensor = torch.load(f\"{self.dir}/oneD_NMR/{self.files[i]}\")   # both\n",
      "/root/MorganFP_prediction/reproduce_previous_works/Spectre/datasets/optional_2d_folder_dataset.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  c_tensor, h_tensor = torch.load(f\"{self.dir}/oneD_NMR/{self.files[i]}\")   # both\n",
      "/root/MorganFP_prediction/reproduce_previous_works/Spectre/datasets/optional_2d_folder_dataset.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  c_tensor, h_tensor = torch.load(f\"{self.dir}/oneD_NMR/{self.files[i]}\")   # both\n",
      "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/transformer.py:502: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. (Triggered internally at ../aten/src/ATen/NestedTensorImpl.cpp:178.)\n",
      "  output = torch._nested_tensor_from_mask(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'on_epoch': True, 'sync_dist': False} \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    test/mean_accuracy     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9895988702774048     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">   test/mean_active_bits   </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     153.9069061279297     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     test/mean_ce_loss     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.07496611028909683    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test/mean_cos       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7967032194137573     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test/mean_f1        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8011723756790161     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     test/mean_jaccard     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6671128869056702     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    test/mean_mean_rank    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     4.148763179779053     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    test/mean_neg_loss     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.019253605976700783    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    test/mean_pos_loss     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.0557125024497509     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">  test/mean_pos_neg_loss   </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.07496611028909683    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    test/mean_precision    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8401734232902527     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     test/mean_rank_1      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9380696415901184     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     test/mean_rank_10     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">      0.986083984375       </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     test/mean_rank_5      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">      0.982177734375       </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     test/mean_recall      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7659697532653809     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m   test/mean_accuracy    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9895988702774048    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m  test/mean_active_bits  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    153.9069061279297    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    test/mean_ce_loss    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.07496611028909683   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test/mean_cos      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7967032194137573    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test/mean_f1       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8011723756790161    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    test/mean_jaccard    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6671128869056702    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   test/mean_mean_rank   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    4.148763179779053    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   test/mean_neg_loss    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.019253605976700783   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   test/mean_pos_loss    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.0557125024497509    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m test/mean_pos_neg_loss  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.07496611028909683   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   test/mean_precision   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8401734232902527    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    test/mean_rank_1     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9380696415901184    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    test/mean_rank_10    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.986083984375      \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    test/mean_rank_5     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.982177734375      \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    test/mean_recall     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7659697532653809    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_model_performance(model);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using jaccard:  False\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "/workspace/ranking_sets_cleaned_by_inchi/SMILES_R0_to_R4_reduced_FP_ranking_sets_only_all_info_molecules/val/rankingset.pt does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m hparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcheckpoint_path\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;66;03m# prevent double defition of checkpoint_path\u001b[39;00m\n\u001b[1;32m     13\u001b[0m hparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muse_peak_values\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mOptionalInputRankedTransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_from_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m model\u001b[38;5;241m.\u001b[39mchange_ranker_for_testing()\n\u001b[1;32m     18\u001b[0m flexible_model_result \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mtest(model, datamodule)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/utilities/model_helpers.py:125\u001b[0m, in \u001b[0;36m_restricted_classmethod_impl.__get__.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m instance \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scripting:\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    122\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe classmethod `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` cannot be called on an instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    123\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Please call it on the class type and make sure the return value is used.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    124\u001b[0m     )\n\u001b[0;32m--> 125\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/core/module.py:1581\u001b[0m, in \u001b[0;36mLightningModule.load_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m   1492\u001b[0m \u001b[38;5;129m@_restricted_classmethod\u001b[39m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_from_checkpoint\u001b[39m(\n\u001b[1;32m   1494\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1499\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m   1500\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Primary way of loading a model from a checkpoint. When Lightning saves a checkpoint it stores the arguments\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;124;03m    passed to ``__init__``  in the checkpoint under ``\"hyper_parameters\"``.\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1579\u001b[0m \n\u001b[1;32m   1580\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1581\u001b[0m     loaded \u001b[38;5;241m=\u001b[39m \u001b[43m_load_from_checkpoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1582\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1583\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhparams_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1587\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1588\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1589\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(Self, loaded)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/core/saving.py:91\u001b[0m, in \u001b[0;36m_load_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _load_state(\u001b[38;5;28mcls\u001b[39m, checkpoint, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, pl\u001b[38;5;241m.\u001b[39mLightningModule):\n\u001b[0;32m---> 91\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43m_load_state\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m     state_dict \u001b[38;5;241m=\u001b[39m checkpoint[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m state_dict:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/core/saving.py:158\u001b[0m, in \u001b[0;36m_load_state\u001b[0;34m(cls, checkpoint, strict, **cls_kwargs_new)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cls_spec\u001b[38;5;241m.\u001b[39mvarkw:\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;66;03m# filter kwargs according to class init unless it allows any argument via kwargs\u001b[39;00m\n\u001b[1;32m    156\u001b[0m     _cls_kwargs \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m _cls_kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m cls_init_args_name}\n\u001b[0;32m--> 158\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_cls_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, pl\u001b[38;5;241m.\u001b[39mLightningDataModule):\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m \u001b[38;5;129;01min\u001b[39;00m checkpoint:\n",
      "File \u001b[0;32m~/MorganFP_prediction/reproduce_previous_works/Spectre/models/optional_input_ranked_transformer.py:8\u001b[0m, in \u001b[0;36mOptionalInputRankedTransformer.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m----> 8\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidation_step_outputs \u001b[38;5;241m=\u001b[39m defaultdict(\u001b[38;5;28mlist\u001b[39m)\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_step_outputs \u001b[38;5;241m=\u001b[39m defaultdict(\u001b[38;5;28mlist\u001b[39m)\n",
      "File \u001b[0;32m~/MorganFP_prediction/reproduce_previous_works/Spectre/models/ranked_transformer.py:125\u001b[0m, in \u001b[0;36mHsqcRankedTransformer.__init__\u001b[0;34m(self, dim_model, dim_coords, heads, layers, ff_dim, coord_enc, wavelength_bounds, gce_resolution, dropout, save_params, ranking_set_path, FP_choice, loss_func, lr, noam_factor, pos_weight, weight_decay, L1_decay, scheduler, warm_up_steps, freeze_weights, use_Jaccard, *args, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mranking_set_path \u001b[38;5;241m=\u001b[39m ranking_set_path\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;66;03m# print(ranking_set_path)\u001b[39;00m\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(ranking_set_path), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mranking_set_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not exist\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mranker \u001b[38;5;241m=\u001b[39m ranker\u001b[38;5;241m.\u001b[39mRankingSet(file_path\u001b[38;5;241m=\u001b[39mranking_set_path, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbs, CE_num_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_class)\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m save_params:\n",
      "\u001b[0;31mAssertionError\u001b[0m: /workspace/ranking_sets_cleaned_by_inchi/SMILES_R0_to_R4_reduced_FP_ranking_sets_only_all_info_molecules/val/rankingset.pt does not exist"
     ]
    }
   ],
   "source": [
    "# spectra-flexible model\n",
    "# usually not gonna use it because it tests right away after training \n",
    "\n",
    "# load model \n",
    "\n",
    "model_path = Path(\"/root/MorganFP_prediction/reproduce_previous_works/average_3/model_sizes/flexible_384_trail1\")\n",
    "hyperpaerameters_path = model_path / \"hparams.yaml\"\n",
    "\n",
    "checkpoint_path = model_path / \"checkpoints/epoch=41-step=35994.ckpt\"\n",
    "with open(hyperpaerameters_path, 'r') as file:\n",
    "    hparams = yaml.safe_load(file)\n",
    "del hparams['checkpoint_path'] # prevent double defition of checkpoint_path\n",
    "hparams['use_peak_values'] = False\n",
    "\n",
    "model = OptionalInputRankedTransformer.load_from_checkpoint(checkpoint_path, **hparams)\n",
    "model.change_ranker_for_testing()\n",
    "\n",
    "flexible_model_result = trainer.test(model, datamodule)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "names = [\"all_inputs\", \"HSQC_H_NMR\", \"HSQC_C_NMR\", \"only_hsqc\", \"only_1d\", \"only_H_NMR\", \"only_C_NMR\"]\n",
    "out_file = \"temp_model_show.txt\"\n",
    "with open(out_file, \"w\") as file:\n",
    "    for name in  names:\n",
    "        file.write(f\"\\n{name:10}: \")\n",
    "        for m in metric_to_focus:\n",
    "            file.write(f\"{m}: {flexible_model_result[0]['test_mean_'+m+'_'+name]:.4f}, \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['test_mean_ce_loss_all_inputs', 'test_mean_pos_loss_all_inputs', 'test_mean_neg_loss_all_inputs', 'test_mean_pos_neg_loss_all_inputs', 'test_mean_cos_all_inputs', 'test_mean_active_bits_all_inputs', 'test_mean_f1_all_inputs', 'test_mean_precision_all_inputs', 'test_mean_recall_all_inputs', 'test_mean_accuracy_all_inputs', 'test_mean_mean_rank_all_inputs', 'test_mean_rank_1_all_inputs', 'test_mean_rank_5_all_inputs', 'test_mean_rank_10_all_inputs', 'test_mean_ce_loss_HSQC_H_NMR', 'test_mean_pos_loss_HSQC_H_NMR', 'test_mean_neg_loss_HSQC_H_NMR', 'test_mean_pos_neg_loss_HSQC_H_NMR', 'test_mean_cos_HSQC_H_NMR', 'test_mean_active_bits_HSQC_H_NMR', 'test_mean_f1_HSQC_H_NMR', 'test_mean_precision_HSQC_H_NMR', 'test_mean_recall_HSQC_H_NMR', 'test_mean_accuracy_HSQC_H_NMR', 'test_mean_mean_rank_HSQC_H_NMR', 'test_mean_rank_1_HSQC_H_NMR', 'test_mean_rank_5_HSQC_H_NMR', 'test_mean_rank_10_HSQC_H_NMR', 'test_mean_ce_loss_HSQC_C_NMR', 'test_mean_pos_loss_HSQC_C_NMR', 'test_mean_neg_loss_HSQC_C_NMR', 'test_mean_pos_neg_loss_HSQC_C_NMR', 'test_mean_cos_HSQC_C_NMR', 'test_mean_active_bits_HSQC_C_NMR', 'test_mean_f1_HSQC_C_NMR', 'test_mean_precision_HSQC_C_NMR', 'test_mean_recall_HSQC_C_NMR', 'test_mean_accuracy_HSQC_C_NMR', 'test_mean_mean_rank_HSQC_C_NMR', 'test_mean_rank_1_HSQC_C_NMR', 'test_mean_rank_5_HSQC_C_NMR', 'test_mean_rank_10_HSQC_C_NMR', 'test_mean_ce_loss_only_hsqc', 'test_mean_pos_loss_only_hsqc', 'test_mean_neg_loss_only_hsqc', 'test_mean_pos_neg_loss_only_hsqc', 'test_mean_cos_only_hsqc', 'test_mean_active_bits_only_hsqc', 'test_mean_f1_only_hsqc', 'test_mean_precision_only_hsqc', 'test_mean_recall_only_hsqc', 'test_mean_accuracy_only_hsqc', 'test_mean_mean_rank_only_hsqc', 'test_mean_rank_1_only_hsqc', 'test_mean_rank_5_only_hsqc', 'test_mean_rank_10_only_hsqc', 'test_mean_ce_loss_only_1d', 'test_mean_pos_loss_only_1d', 'test_mean_neg_loss_only_1d', 'test_mean_pos_neg_loss_only_1d', 'test_mean_cos_only_1d', 'test_mean_active_bits_only_1d', 'test_mean_f1_only_1d', 'test_mean_precision_only_1d', 'test_mean_recall_only_1d', 'test_mean_accuracy_only_1d', 'test_mean_mean_rank_only_1d', 'test_mean_rank_1_only_1d', 'test_mean_rank_5_only_1d', 'test_mean_rank_10_only_1d', 'test_mean_ce_loss_only_H_NMR', 'test_mean_pos_loss_only_H_NMR', 'test_mean_neg_loss_only_H_NMR', 'test_mean_pos_neg_loss_only_H_NMR', 'test_mean_cos_only_H_NMR', 'test_mean_active_bits_only_H_NMR', 'test_mean_f1_only_H_NMR', 'test_mean_precision_only_H_NMR', 'test_mean_recall_only_H_NMR', 'test_mean_accuracy_only_H_NMR', 'test_mean_mean_rank_only_H_NMR', 'test_mean_rank_1_only_H_NMR', 'test_mean_rank_5_only_H_NMR', 'test_mean_rank_10_only_H_NMR', 'test_mean_ce_loss_only_C_NMR', 'test_mean_pos_loss_only_C_NMR', 'test_mean_neg_loss_only_C_NMR', 'test_mean_pos_neg_loss_only_C_NMR', 'test_mean_cos_only_C_NMR', 'test_mean_active_bits_only_C_NMR', 'test_mean_f1_only_C_NMR', 'test_mean_precision_only_C_NMR', 'test_mean_recall_only_C_NMR', 'test_mean_accuracy_only_C_NMR', 'test_mean_mean_rank_only_C_NMR', 'test_mean_rank_1_only_C_NMR', 'test_mean_rank_5_only_C_NMR', 'test_mean_rank_10_only_C_NMR'])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flexible_model_result[0] .keys()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
