{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "920f4e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "choosing Hash_Entropy_FP_loader\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, message=\"You are using `torch.load` with `weights_only=False`\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"The PyTorch API of nested tensors is in prototype stage and will change in the near future.\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys, os\n",
    "sys.path.insert(0,\"/root/gurusmart/MorganFP_prediction/reproduce_previous_works/Spectre\")\n",
    "            \n",
    "import torch\n",
    "torch.set_printoptions(precision=10)\n",
    "\n",
    "\n",
    "import yaml\n",
    "torch.set_float32_matmul_precision('high')\n",
    "from pathlib import Path\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "# load model \n",
    "from datasets.dataset_utils import  fp_loader_configer\n",
    "\n",
    "fp_loader_configer.select_version(\"Hash_Entropy\")\n",
    "fp_loader = fp_loader_configer.fp_loader\n",
    "\n",
    "import numpy as np \n",
    "import random\n",
    "seed=2\n",
    "torch.cuda.manual_seed_all(seed) \n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "259682f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "526316\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open(f'/root/gurusmart/MorganFP_prediction/inference_data/coconut_loutus_hyun_training/inference_metadata_latest_RDkit.pkl', 'rb') as file:\n",
    "    smiles_and_names = pickle.load(file)\n",
    "print(len(smiles_and_names))\n",
    "\n",
    "from inference.inference_utils import choose_model\n",
    "from inference.inference_utils import save_molecule_inference\n",
    "from inference.inference_utils import retrieve_top_k_by_rankingset, compute_cos_sim, unpack_inputs_no_delimiter, build_input, inference_topK\n",
    "from utils.get_NP_class import get_superclass_and_glycoside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec3b4083",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_smiles_from_dir(compound_dir):\n",
    "    with open(Path(compound_dir) / \"SMILES.txt\", \"r\") as f:\n",
    "        smiles = f.read().strip()\n",
    "    return smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "da608f44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['new_compound_B1',\n",
       " 'Aculeapyridone A',\n",
       " 'Kavaratamide A',\n",
       " 'new_compound_A',\n",
       " 'Rhodomollein LVII',\n",
       " 'Monchicamide I',\n",
       " 'Wrightioside A',\n",
       " 'Contignasterine A',\n",
       " 'methyl_beta-D-glucopyranoside',\n",
       " 'Glycyasymmetrica A',\n",
       " 'Jejupeptin A',\n",
       " 'Indanopyrrole A',\n",
       " 'get_mw_weights_for_new_mols.ipynb',\n",
       " 'new_compound_B2',\n",
       " 'Fatuamide A']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"/root/gurusmart/MorganFP_prediction/reproduce_previous_works/Spectre/datasets/testing_compounds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aee18126",
   "metadata": {},
   "outputs": [],
   "source": [
    "compounds_names = [\n",
    "    'new_compound_B1',\n",
    " 'Aculeapyridone A',\n",
    " 'Kavaratamide A',\n",
    " 'new_compound_A',\n",
    " 'Rhodomollein LVII',\n",
    " 'Monchicamide I',\n",
    " 'Wrightioside A',\n",
    " 'Contignasterine A',\n",
    "#  'methyl_beta-D-glucopyranoside',\n",
    " 'Glycyasymmetrica A',\n",
    " 'Jejupeptin A',\n",
    " 'Indanopyrrole A',\n",
    " 'new_compound_B2',\n",
    " 'Fatuamide A']\n",
    "\n",
    "# [\n",
    "#  'Aculeapyridone A',\n",
    "#  'Contignasterine A',\n",
    "#  'Glycyasymmetrica A',\n",
    "#  'Rhodomollein LVII',\n",
    "#  'Monchicamide I',\n",
    "#  'Wrightioside A',\n",
    "#  'Jejupeptin A',\n",
    "#  'Indanopyrrole A',\n",
    "#  'Fatuamide A'\n",
    "#  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d695e2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_cosine_in_annotation(model):\n",
    "    all_cos = []\n",
    "    for compound_dir in [f\"/root/gurusmart/MorganFP_prediction/reproduce_previous_works/Spectre/datasets/testing_compounds/{name}\" for name in compounds_names]:\n",
    "        inputs, NMR_type_indicator = build_input(compound_dir, mode='None',\n",
    "                            include_h_nmr=False, include_c_nmr=False, include_hsqc=True,\n",
    "                            )\n",
    "        inputs = inputs.unsqueeze(0).to(model.device)\n",
    "        NMR_type_indicator = NMR_type_indicator.to(model.device)\n",
    "    \n",
    "        ground_smiles = get_smiles_from_dir(compound_dir)\n",
    "        ground_FP = fp_loader.build_mfp_for_new_SMILES(ground_smiles).to(model.device)\n",
    "        \n",
    "        pred = model(inputs, NMR_type_indicator)\n",
    "        pred = torch.sigmoid(pred) # sigmoid\n",
    "        cosine = compute_cos_sim(pred, ground_FP)\n",
    "        all_cos.append(cosine)\n",
    "    all_cos = np.array(all_cos)\n",
    "    avg_cos = np.mean(all_cos)\n",
    "   \n",
    "    return avg_cos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a42ebcb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from:  /root/gurusmart/MorganFP_prediction/reproduce_previous_works/entropy_on_hashes/all_HSQC_jittering_search/only_hsqc_jittering_0.5-trial-1/checkpoints/epoch=88-step=38181.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialized SignCoordinateEncoder[784] with dims [365, 365, 54] and 2 positional encoders. 54 bits are reserved for encoding the final bit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HsqcRankedTransformer saving args\n",
      "Hash_Entropy_FP_loader is already setup\n",
      "loading model from:  /root/gurusmart/MorganFP_prediction/reproduce_previous_works/entropy_on_hashes/all_HSQC_jittering_search/only_hsqc_jittering_0.25-trial-2/checkpoints/epoch=50-step=21879.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialized SignCoordinateEncoder[784] with dims [365, 365, 54] and 2 positional encoders. 54 bits are reserved for encoding the final bit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HsqcRankedTransformer saving args\n",
      "Hash_Entropy_FP_loader is already setup\n",
      "loading model from:  /root/gurusmart/MorganFP_prediction/reproduce_previous_works/entropy_on_hashes/all_HSQC_jittering_search/only_hsqc_jittering_2-trial-1/checkpoints/epoch=71-step=30888.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialized SignCoordinateEncoder[784] with dims [365, 365, 54] and 2 positional encoders. 54 bits are reserved for encoding the final bit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HsqcRankedTransformer saving args\n",
      "Hash_Entropy_FP_loader is already setup\n",
      "loading model from:  /root/gurusmart/MorganFP_prediction/reproduce_previous_works/entropy_on_hashes/all_HSQC_jittering_search/only_hsqc_jittering_0-trial-1/checkpoints/epoch=73-step=31746.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialized SignCoordinateEncoder[784] with dims [365, 365, 54] and 2 positional encoders. 54 bits are reserved for encoding the final bit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HsqcRankedTransformer saving args\n",
      "Hash_Entropy_FP_loader is already setup\n",
      "loading model from:  /root/gurusmart/MorganFP_prediction/reproduce_previous_works/entropy_on_hashes/all_HSQC_jittering_search/only_hsqc_jittering_0.25-trial-3/checkpoints/epoch=110-step=47619.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialized SignCoordinateEncoder[784] with dims [365, 365, 54] and 2 positional encoders. 54 bits are reserved for encoding the final bit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HsqcRankedTransformer saving args\n",
      "Hash_Entropy_FP_loader is already setup\n",
      "loading model from:  /root/gurusmart/MorganFP_prediction/reproduce_previous_works/entropy_on_hashes/all_HSQC_jittering_search/only_hsqc_jittering_0.25-trial-1/checkpoints/epoch=63-step=27456.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialized SignCoordinateEncoder[784] with dims [365, 365, 54] and 2 positional encoders. 54 bits are reserved for encoding the final bit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HsqcRankedTransformer saving args\n",
      "Hash_Entropy_FP_loader is already setup\n",
      "loading model from:  /root/gurusmart/MorganFP_prediction/reproduce_previous_works/entropy_on_hashes/all_HSQC_jittering_search/only_hsqc_jittering_2-trial-3/checkpoints/epoch=82-step=35607.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialized SignCoordinateEncoder[784] with dims [365, 365, 54] and 2 positional encoders. 54 bits are reserved for encoding the final bit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HsqcRankedTransformer saving args\n",
      "Hash_Entropy_FP_loader is already setup\n",
      "loading model from:  /root/gurusmart/MorganFP_prediction/reproduce_previous_works/entropy_on_hashes/all_HSQC_jittering_search/only_hsqc_jittering_1-trial-1/checkpoints/epoch=82-step=35607.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialized SignCoordinateEncoder[784] with dims [365, 365, 54] and 2 positional encoders. 54 bits are reserved for encoding the final bit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HsqcRankedTransformer saving args\n",
      "Hash_Entropy_FP_loader is already setup\n",
      "loading model from:  /root/gurusmart/MorganFP_prediction/reproduce_previous_works/entropy_on_hashes/all_HSQC_jittering_search/only_hsqc_jittering_0.5-trial-3/checkpoints/epoch=64-step=27885.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialized SignCoordinateEncoder[784] with dims [365, 365, 54] and 2 positional encoders. 54 bits are reserved for encoding the final bit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HsqcRankedTransformer saving args\n",
      "Hash_Entropy_FP_loader is already setup\n",
      "loading model from:  /root/gurusmart/MorganFP_prediction/reproduce_previous_works/entropy_on_hashes/all_HSQC_jittering_search/only_hsqc_jittering_0-trial-3/checkpoints/epoch=83-step=36036.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialized SignCoordinateEncoder[784] with dims [365, 365, 54] and 2 positional encoders. 54 bits are reserved for encoding the final bit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HsqcRankedTransformer saving args\n",
      "Hash_Entropy_FP_loader is already setup\n",
      "loading model from:  /root/gurusmart/MorganFP_prediction/reproduce_previous_works/entropy_on_hashes/all_HSQC_jittering_search/only_hsqc_jittering_2-trial-2/checkpoints/epoch=65-step=28314.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialized SignCoordinateEncoder[784] with dims [365, 365, 54] and 2 positional encoders. 54 bits are reserved for encoding the final bit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HsqcRankedTransformer saving args\n",
      "Hash_Entropy_FP_loader is already setup\n",
      "loading model from:  /root/gurusmart/MorganFP_prediction/reproduce_previous_works/entropy_on_hashes/all_HSQC_jittering_search/only_hsqc_jittering_1-trial-2/checkpoints/epoch=88-step=38181.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialized SignCoordinateEncoder[784] with dims [365, 365, 54] and 2 positional encoders. 54 bits are reserved for encoding the final bit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HsqcRankedTransformer saving args\n",
      "Hash_Entropy_FP_loader is already setup\n",
      "loading model from:  /root/gurusmart/MorganFP_prediction/reproduce_previous_works/entropy_on_hashes/all_HSQC_jittering_search/only_hsqc_jittering_0-trial-2/checkpoints/epoch=98-step=42471.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialized SignCoordinateEncoder[784] with dims [365, 365, 54] and 2 positional encoders. 54 bits are reserved for encoding the final bit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HsqcRankedTransformer saving args\n",
      "Hash_Entropy_FP_loader is already setup\n",
      "loading model from:  /root/gurusmart/MorganFP_prediction/reproduce_previous_works/entropy_on_hashes/all_HSQC_jittering_search/only_hsqc_jittering_0.5-trial-2/checkpoints/epoch=84-step=36465.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialized SignCoordinateEncoder[784] with dims [365, 365, 54] and 2 positional encoders. 54 bits are reserved for encoding the final bit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HsqcRankedTransformer saving args\n",
      "Hash_Entropy_FP_loader is already setup\n",
      "loading model from:  /root/gurusmart/MorganFP_prediction/reproduce_previous_works/entropy_on_hashes/all_HSQC_jittering_search/only_hsqc_jittering_1-trial-3/checkpoints/epoch=90-step=39039.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialized SignCoordinateEncoder[784] with dims [365, 365, 54] and 2 positional encoders. 54 bits are reserved for encoding the final bit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HsqcRankedTransformer saving args\n",
      "Hash_Entropy_FP_loader is already setup\n",
      "jittering amount is 0.5\n",
      "0.6786624995561746 0.009511074452518697\n",
      "\n",
      "jittering amount is 0.25\n",
      "0.6663055328222421 0.016661124762008567\n",
      "\n",
      "jittering amount is 2\n",
      "0.6937822882945722 0.006769678955399707\n",
      "\n",
      "jittering amount is 0\n",
      "0.6521557240914075 0.014063617548182236\n",
      "\n",
      "jittering amount is 1\n",
      "0.6971921049631559 0.014660908359677923\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "exp_dir = \"/root/gurusmart/MorganFP_prediction/reproduce_previous_works/entropy_on_hashes/all_HSQC_jittering_search/\"\n",
    "jittering_dict = defaultdict(list)\n",
    "for root, _, files in os.walk(exp_dir):\n",
    "    \n",
    "    for file in files:\n",
    "        if file.endswith(\".ckpt\"):\n",
    "            hparams, model = choose_model(\"\", checkpoint_path=os.path.join(root, file))\n",
    "            cos_score = get_avg_cosine_in_annotation(model)\n",
    "            jitter = root.split(\"jittering_\")[-1].split(\"-trial\")[0]\n",
    "            jittering_dict[jitter].append(cos_score)\n",
    "\n",
    "for k, v in jittering_dict.items():\n",
    "    print(f\"jittering amount is {k}\")\n",
    "    print(np.mean(v), np.std(v))\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5fcb554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jittering amount is epoch=90-step=39039\n",
      "0.6580117841561636 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k, v in jittering_dict.items():\n",
    "    print(f\"jittering amount is {k}\")\n",
    "    print(np.mean(v), np.std(v))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0e3cc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
