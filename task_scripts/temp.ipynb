{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pickle\n",
    "oneD_dataset_root_path = '/workspace/OneD_Only_Dataset'\n",
    "files = os.listdir(oneD_dataset_root_path+\"/train/oneD_NMR\")\n",
    "from pathlib import Path\n",
    "import torch, tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101.29000091552734, 71.36000061035156, 73.70999908447266, 77.6500015258789, 77.05000305175781, 55.65999984741211, 62.2400016784668] [3.7200000286102295, 3.75, 4.170000076293945, 5.440000057220459, 4.119999885559082, 3.799999952316284]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24307/2937912545.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  a = torch.load('/workspace/SMILES_dataset/test/oneD_NMR/10002.pt')\n"
     ]
    }
   ],
   "source": [
    "a = torch.load('/workspace/SMILES_dataset/test/oneD_NMR/10002.pt')\n",
    "print(a[0].tolist(), a[1].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24307/4257511784.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  b= torch.load('/workspace/SMILES_dataset/test/HSQC/10002.pt')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[4.4991397857666, 99.5999984741211, 5325.9169921875],\n",
       " [3.6824898719787598, 73.5999984741211, 7687.54296875],\n",
       " [3.62517857551575, 71.9000015258789, 6256.4423828125],\n",
       " [3.82882905006409, 71.5999984741211, 9228.2744140625],\n",
       " [3.7761032581329306, 70.09999847412111, 7007.5],\n",
       " [3.7864191532134996, 61.2000007629395, -5335.78466796875],\n",
       " [3.70228123664856, 61.2000007629395, -4389.5302734375],\n",
       " [3.3812499046325697, 55.30000305175779, 15977.751953125]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b= torch.load('/workspace/SMILES_dataset/test/HSQC/10002.pt')\n",
    "b[:,[0,1]] = b[:,[1,0]]\n",
    "b.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "194.079"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "with open('/workspace/SMILES_dataset/test/MW/index.pkl','rb') as r:\n",
    "    index = pickle.load(r)\n",
    "index[10002]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('/root/gurusmart/data/NP-MRD-dataset/NP-MRD_metadata/npmrd_natural_products.json') as f:\n",
    "    data = json.load(f)\n",
    "names_to_npmrd_id = dict([[d['name'], d['accession'] ]for d in data['np_mrd']['natural_product']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# npmrd_id_to_names = dict([v,k] for k,v in names_to_npmrd_id.items())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{oneD_dataset_root_path}/train/Chemical/index.pkl','rb') as r:\n",
    "    chemicals = pickle.load(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name is 6,7-dihydroxy-4-oxo-3-(3-oxobutanoyl)-2,3-dihydro-1-benzopyran-5-carboxylic acid\n",
      "NP-MRD ID: NP0305814\n",
      "H NMR: ['2.19', '2.83', '2.89', '4.04', '6.76']\n",
      "\n",
      "Name is 3,3,6b,10,10,12a,12b,14a-octamethyl-tetradecahydro-1h-piceno[13,12b-b]oxiren-9-ol\n",
      "NP-MRD ID: NP0152610\n",
      "H NMR: ['0.83', '0.90', '0.94', '0.95', '1.02', '1.13', '1.38', '1.46', '1.49', '1.54', '1.59', '1.63', '1.66', '1.72', '1.88', '2.04', '2.29', '3.32', '3.37']\n",
      "\n",
      "Name is 11-(3-bromo-4-hydroxyphenyl)-n-[5,8,11,14-tetrahydroxy-6,9-bis(c-hydroxycarbonimidoylmethyl)-12-isopropyl-16-methyl-2-oxo-3-(sec-butyl)-1-oxa-4,7,10,13-tetraazacyclohexadeca-4,7,10,13-tetraen-15-yl]undeca-2,4,6,8,10-pentaenimidic acid\n",
      "NP-MRD ID: NP0238649\n",
      "H NMR: ['0.82', '0.85', '1.03', '1.30', '1.33', '2.05', '2.19', '2.83', '4.03', '4.28', '4.60', '4.92', '6.16', '6.56', '6.73', '6.83', '6.87', '7.09', '7.31', '7.69']\n",
      "\n",
      "Name is (-)-Coriarioside A\n",
      "NP-MRD ID: NP0081566\n",
      "H NMR: ['0.69', '0.71', '1.00', '1.13', '1.27', '1.30', '1.39', '1.47', '1.59', '1.62', '1.75', '1.80', '1.83', '1.92', '2.00', '2.12', '2.17', '2.86', '2.99', '3.49', '3.63', '3.75', '3.85', '3.89', '4.05', '4.12', '4.25', '4.37', '4.62', '5.18', '5.40', '5.85', '6.65', '7.28']\n",
      "\n",
      "Name is 2-(pentacosa-7,9-diyn-1-yl)furan\n",
      "NP-MRD ID: NP0305245\n",
      "H NMR: ['0.88', '1.22', '1.23', '1.24', '1.25', '1.26', '1.27', '1.34', '1.36', '1.59', '2.30', '2.58', '5.95', '6.11', '7.01']\n",
      "\n",
      "Name is [(2r,3s,4r,5r,6s)-3-{[(2s,3r,4s,5s)-3,4-dihydroxy-5-[(1s)-1-hydroxyethyl]oxolan-2-yl]oxy}-6-{[2-(3,4-dihydroxyphenyl)-5,7-dihydroxy-4-oxochromen-3-yl]oxy}-4,5-dihydroxyoxan-2-yl]methyl acetate\n",
      "NP-MRD ID: NP0278831\n",
      "H NMR: ['1.22', '2.02', '3.81', '3.94', '3.97', '4.04', '4.15', '4.16', '4.19', '4.70', '5.18', '5.25', '6.23', '6.43', '6.90', '7.56', '7.60']\n",
      "\n",
      "Name is (2r,4as,8s,8ar)-8-[2-(6,7-dihydroxy-2,5-dimethylnaphthalen-1-yl)ethyl]-2,4a,8-trimethyl-7-methylidene-hexahydronaphthalene-2-carboxylic acid\n",
      "NP-MRD ID: NP0192762\n",
      "H NMR: ['1.13', '1.14', '1.16', '1.48', '1.72', '1.78', '2.04', '2.11', '2.37', '2.46', '2.55', '3.04', '4.98', '7.14', '7.19', '7.65']\n",
      "\n",
      "Name is E,E-5-Methyl-4-(3,7,11-trimethyl-2,6,10-dodecatrienyl)-1,3-dimethoxybenzene\n",
      "NP-MRD ID: NP0066422\n",
      "H NMR: ['1.62', '1.68', '2.12', '2.17', '2.38', '2.58', '3.89', '5.20', '7.22']\n",
      "\n",
      "Name is methyl (1s,9s,14e,15r,17s,18r)-14-ethylidene-2,12-diazapentacyclo[13.2.1.0¹,⁹.0³,⁸.0¹²,¹⁷]octadeca-3,5,7-triene-18-carboxylate\n",
      "NP-MRD ID: NP0197560\n",
      "H NMR: ['1.65', '1.80', '2.11', '2.80', '2.83', '2.99', '3.31', '3.52', '3.56', '4.28', '5.45', '6.88', '7.15', '7.22', '7.23']\n",
      "\n",
      "Name is 3-[(2r,3r)-7-hydroxy-2,3-dimethyl-6,6-bis(3-methylbut-2-en-1-yl)-4,5-dioxo-2,3-dihydro-1-benzopyran-8-yl]hexanoic acid\n",
      "NP-MRD ID: NP0158727\n",
      "H NMR: ['0.89', '1.13', '1.32', '1.37', '1.58', '1.66', '2.22', '2.60', '2.83', '3.03', '4.58', '5.31']\n",
      "\n",
      "Name is Panaxydol\n",
      "NP-MRD ID: NP0137004\n",
      "H NMR: ['0.88', '1.26', '1.27', '1.39', '1.80', '2.45', '3.36', '3.59', '5.32', '5.89']\n",
      "\n",
      "Name is Taberpsychine\n",
      "NP-MRD ID: NP0139502\n",
      "H NMR: ['1.65', '1.88', '2.61', '2.83', '2.99', '3.21', '3.60', '3.77', '4.04', '5.45', '6.27', '7.13', '7.18', '7.35', '7.52']\n",
      "\n",
      "Name is n-[(10r)-5-hydroxy-3,4,14-trimethoxy-13-oxotricyclo[9.5.0.0²,⁷]hexadeca-1(16),2,4,6,11,14-hexaen-10-yl]ethanimidic acid\n",
      "NP-MRD ID: NP0311828\n",
      "H NMR: ['1.84', '2.13', '2.45', '3.77', '3.95', '4.01', '4.28', '6.63', '6.90', '7.36', '7.63']\n",
      "\n",
      "Name is Floricolin H\n",
      "NP-MRD ID: NP0015676\n",
      "H NMR: []\n",
      "\n",
      "Name is (-)-Brodiosaponin A\n",
      "NP-MRD ID: NP0083242\n",
      "H NMR: ['0.69', '0.71', '0.94', '1.38', '1.59', '1.83', '1.86', '2.00', '2.09', '2.12', '2.16', '2.17', '3.49', '3.75', '3.84', '3.85', '3.87', '3.89', '4.05', '4.12', '4.37', '5.18', '7.36']\n",
      "\n",
      "Name is Bryoflavone\n",
      "NP-MRD ID: NP0054403\n",
      "H NMR: ['6.09', '6.12', '6.51', '6.71', '6.78', '6.93', '7.06', '8.19']\n",
      "\n",
      "Name is 2-(cyclohex-2-en-1-yl)ethanol\n",
      "NP-MRD ID: NP0015618\n",
      "H NMR: []\n",
      "\n",
      "Name is (3r,4s,5s,10s)-4-hydroxy-9-thia-11,15,20-triazaheptacyclo[12.6.1.1³,¹⁰.0²,¹².0³,⁸.0⁵,²⁰.0¹⁷,²¹]docosa-1,7,11,14(21),16-pentaene-6,13-dione\n",
      "NP-MRD ID: NP0166462\n",
      "H NMR: ['2.01', '2.90', '3.34', '4.28', '4.42', '5.53', '6.74', '7.51']\n",
      "\n",
      "Name is 16alpha-Acetoxybuxabenzamidienine\n",
      "NP-MRD ID: NP0069437\n",
      "H NMR: ['0.69', '0.95', '1.39', '1.59', '1.66', '1.83', '1.87', '2.00', '2.12', '2.13', '2.17', '2.86', '2.92', '3.00', '3.49', '4.05', '7.28', '7.36', '7.82', '7.83']\n",
      "\n",
      "Name is Radulanin L\n",
      "NP-MRD ID: NP0061375\n",
      "H NMR: ['1.86', '2.32', '2.64', '2.91', '3.74', '6.65', '6.90', '6.91', '7.28', '7.29']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24307/3426565995.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  c_NMR, h_NMR = torch.load(oneD_dataset_root_path+\"/train/oneD_NMR/\"+f)\n"
     ]
    }
   ],
   "source": [
    "for f in files[800:820]:\n",
    "    index = int(f.split('.')[0])\n",
    "    name = chemicals[index]\n",
    "    print(f\"Name is {name}\\nNP-MRD ID:\",names_to_npmrd_id[name])\n",
    "    c_NMR, h_NMR = torch.load(oneD_dataset_root_path+\"/train/oneD_NMR/\"+f)\n",
    "    print(\"H NMR:\",[ f\"{x:.2f}\" for x in sorted(h_NMR.tolist())]) \n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 340/265316 [00:57<12:22:07,  5.95it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 36\u001b[0m\n\u001b[1;32m     34\u001b[0m npmrd_files_txt_only \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mlistdir(NP_MRD_FILES_dir)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtqdm(npmrd_files_txt_only):\n\u001b[0;32m---> 36\u001b[0m     c, h \u001b[38;5;241m=\u001b[39m \u001b[43mget_nmr_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mNP_MRD_FILES_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(h) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mmax\u001b[39m(h)\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m0.5\u001b[39m:\n\u001b[1;32m     38\u001b[0m             \u001b[38;5;66;03m# print(h_tensor)\u001b[39;00m\n\u001b[1;32m     39\u001b[0m             weird_H_file_paths\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 8\u001b[0m, in \u001b[0;36mget_nmr_tensors\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;66;03m# print('ys')\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m file:\n\u001b[1;32m     10\u001b[0m             parts \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(parts) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parts[\u001b[38;5;241m2\u001b[39m]:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/codecs.py:319\u001b[0m, in \u001b[0;36mBufferedIncrementalDecoder.decode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_buffer_decode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, errors, final):\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;66;03m# Overwrite this method in subclasses: It must decode input\u001b[39;00m\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;66;03m# and return an (output, length consumed) tuple\u001b[39;00m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n\u001b[0;32m--> 319\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;66;03m# decode input (taking the buffer into account)\u001b[39;00m\n\u001b[1;32m    321\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer \u001b[38;5;241m+\u001b[39m \u001b[38;5;28minput\u001b[39m\n\u001b[1;32m    322\u001b[0m     (result, consumed) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer_decode(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merrors, final)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def get_nmr_tensors(file_path):\n",
    "    c_values = set()\n",
    "    h_values = set()\n",
    "\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            # print('ys')\n",
    "            for line in file:\n",
    "              \n",
    "                parts = line.strip().split(',')\n",
    "                if len(parts) < 3 or not parts[2]:\n",
    "                    continue  # Skip lines that don't have enough parts or the third column is empty\n",
    "\n",
    "                element, _, value, *_ = parts\n",
    "                value = float(value)\n",
    "\n",
    "                if element == 'C':\n",
    "                    c_values.add(value)\n",
    "                elif element == 'H':\n",
    "                    h_values.add(value)\n",
    "    except Exception as e:\n",
    "        print(\"error\", e)\n",
    "        print(\"file_path\", file_path)\n",
    "        \n",
    "        \n",
    "    # Convert sets to tensors\n",
    "    c_tensor = torch.tensor(list(c_values), dtype=torch.float32)\n",
    "    h_tensor = torch.tensor(list(h_values), dtype=torch.float32)\n",
    "    # print(\"returning\")\n",
    "    return c_tensor, h_tensor\n",
    "\n",
    "weird_H_file_paths = []\n",
    "NP_MRD_FILES_dir = '/root/gurusmart/data/NP-MRD-dataset/NP-MRD-shift-assignments'\n",
    "npmrd_files_txt_only = os.listdir(NP_MRD_FILES_dir)\n",
    "for f in tqdm.tqdm(npmrd_files_txt_only):\n",
    "    c, h = get_nmr_tensors(NP_MRD_FILES_dir + '/' + f)\n",
    "    if len(h) and max(h)<0.5:\n",
    "            # print(h_tensor)\n",
    "            weird_H_file_paths.append(f\"{f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only C: 1122 | Only H: 2 | Both C and H: 19011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1866/1866 [06:54<00:00,  4.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only C: 1147 | Only H: 4 | Both C and H: 19163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1843/1843 [06:33<00:00,  4.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only C: 9127 | Only H: 33 | Both C and H: 153513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14989/14989 [52:11<00:00,  4.79it/s] \n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset_path= Path('/workspace/OneD_Only_Dataset/')\n",
    "\n",
    "for split in ['test', 'val', \"train\"]:\n",
    "\n",
    "    index_to_chemical_name = pickle.load(open(dataset_path / split / 'Chemical/index.pkl', 'rb'))\n",
    "    chemical_name_to_indx = dict([[v,k] for k,v in index_to_chemical_name.items()])\n",
    "    path_1d = Path( dataset_path / split)\n",
    "    oneD_NMRs = os.listdir(path_1d/'oneD_NMR')\n",
    "    # look for both empty tensors\n",
    "    only_c, only_h, c_and_h = 0, 0, 0\n",
    "    empty = []\n",
    "    for i in oneD_NMRs:\n",
    "        c_tensor, h_tensor = torch.load(path_1d / 'oneD_NMR'/ i)\n",
    "        if len(c_tensor) > 0 and len(h_tensor) > 0:\n",
    "            c_and_h += 1\n",
    "        elif len(c_tensor) > 0:\n",
    "            only_c += 1\n",
    "        elif len(h_tensor) > 0:\n",
    "            only_h += 1\n",
    "        else:\n",
    "            empty.append(i)\n",
    "            \n",
    "    print(f'Only C: {only_c} | Only H: {only_h} | Both C and H: {c_and_h}')\n",
    "\n",
    "\n",
    "    np_ids_with_empty_tensors = [names_to_npmrd_id[index_to_chemical_name[int(file_index.split(\".\")[0])]] for file_index in empty]\n",
    "    txt_file_locations = filter(lambda x: x.split(\"_\")[0] in np_ids_with_empty_tensors, npmrd_files_txt_only)\n",
    "\n",
    "    txt_file_locations= list(txt_file_locations)\n",
    "    assert (len(txt_file_locations) == len (empty))\n",
    "\n",
    "\n",
    "    for txt_f in tqdm.tqdm(txt_file_locations):\n",
    "        chemical_name = npmrd_id_to_names [txt_f.split(\"_\")[0]]\n",
    "        file_index = chemical_name_to_indx[chemical_name]\n",
    "        save_path = dataset_path / split / 'oneD_NMR' / f\"{file_index}.pt\"\n",
    "        \n",
    "        c_values = set()\n",
    "        h_values = set()\n",
    "        with open(Path(NP_MRD_FILES_dir) / txt_f) as f:\n",
    "            \n",
    "            try:\n",
    "                for line in f:\n",
    "                    parts = line.strip().split('\\t')\n",
    "                    if len(parts) < 3 or not parts[2]:\n",
    "                        continue  # Skip lines that don't have enough parts or the third column is empty\n",
    "\n",
    "                    id, element, value, *_ = parts\n",
    "                    # print(element, value)\n",
    "                    if value in [\"chemical_shift\", \"shift\", \"NA\"]:\n",
    "                        continue\n",
    "                    \n",
    "                    value = float(value)\n",
    "\n",
    "                    if element == 'C':\n",
    "                        c_values.add(value)\n",
    "                    elif element == 'H':\n",
    "                        h_values.add(value)\n",
    "                if len(c_values)==0 and len(h_values)==0:\n",
    "                    print(\"No c and H\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(txt_f)\n",
    "                print(element, value )\n",
    "                print(parts)               \n",
    "                    \n",
    "                raise(e)\n",
    "        c_tensor = torch.tensor(list(c_values), dtype=torch.float32)\n",
    "        h_tensor = torch.tensor(list(h_values), dtype=torch.float32)\n",
    "        torch.save([c_tensor, h_tensor], save_path)\n",
    "        \n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 27350/280242 [00:06<01:19, 3187.58it/s][01:59:19] Conflicting single bond directions around double bond at index 2.\n",
      "[01:59:19]   BondStereo set to STEREONONE and single bond directions set to NONE.\n",
      " 15%|█▍        | 40951/280242 [00:11<01:10, 3380.46it/s][01:59:23] WARNING: not removing hydrogen atom without neighbors\n",
      "[01:59:23] WARNING: not removing hydrogen atom without neighbors\n",
      " 15%|█▌        | 42903/280242 [00:11<00:53, 4421.50it/s][01:59:24] WARNING: not removing hydrogen atom without neighbors\n",
      "[01:59:24] WARNING: not removing hydrogen atom without neighbors\n",
      "[01:59:24] WARNING: not removing hydrogen atom without neighbors\n",
      " 16%|█▌        | 44741/280242 [00:12<00:44, 5292.58it/s][01:59:24] WARNING: not removing hydrogen atom without neighbors\n",
      " 18%|█▊        | 51591/280242 [00:13<01:02, 3655.43it/s][01:59:26] Can't kekulize mol.  Unkekulized atoms: 2 3 31\n",
      "[01:59:26] WARNING:  Problems/mismatches: Mobile-H( Mobile-H groups: Attachment points, Number)\n",
      "\n",
      " 21%|██        | 58499/280242 [00:15<00:56, 3921.12it/s][01:59:27] Explicit valence for atom # 2 N, 4, is greater than permitted\n",
      "[01:59:27] Explicit valence for atom # 9 N, 4, is greater than permitted\n",
      "[01:59:27] ERROR: Explicit valence for atom # 9 N, 4, is greater than permitted\n",
      "\n",
      " 21%|██        | 58899/280242 [00:15<00:58, 3807.48it/s][01:59:27] Explicit valence for atom # 10 O, 3, is greater than permitted\n",
      "[01:59:27] Explicit valence for atom # 40 B, 7, is greater than permitted\n",
      "[01:59:27] ERROR: Explicit valence for atom # 40 B, 7, is greater than permitted\n",
      "\n",
      " 23%|██▎       | 64253/280242 [00:16<00:45, 4797.80it/s][01:59:28] Explicit valence for atom # 20 N, 4, is greater than permitted\n",
      "[01:59:28] Explicit valence for atom # 20 N, 4, is greater than permitted\n",
      "[01:59:28] ERROR: Explicit valence for atom # 20 N, 4, is greater than permitted\n",
      "\n",
      " 24%|██▎       | 66093/280242 [00:17<00:48, 4432.51it/s][01:59:29] Explicit valence for atom # 24 N, 4, is greater than permitted\n",
      "[01:59:29] Explicit valence for atom # 21 N, 4, is greater than permitted\n",
      "[01:59:29] ERROR: Explicit valence for atom # 21 N, 4, is greater than permitted\n",
      "\n",
      " 24%|██▎       | 66538/280242 [00:17<00:49, 4325.14it/s][01:59:29] Explicit valence for atom # 17 N, 4, is greater than permitted\n",
      "[01:59:29] Explicit valence for atom # 22 N, 4, is greater than permitted\n",
      "[01:59:29] ERROR: Explicit valence for atom # 22 N, 4, is greater than permitted\n",
      "\n",
      " 24%|██▍       | 66972/280242 [00:17<00:51, 4157.94it/s][01:59:29] Explicit valence for atom # 4 N, 4, is greater than permitted\n",
      "[01:59:29] Explicit valence for atom # 21 N, 4, is greater than permitted\n",
      "[01:59:29] ERROR: Explicit valence for atom # 21 N, 4, is greater than permitted\n",
      "\n",
      " 24%|██▍       | 67390/280242 [00:17<00:52, 4070.22it/s][01:59:29] Explicit valence for atom # 9 N, 4, is greater than permitted\n",
      " 25%|██▍       | 69652/280242 [00:18<01:00, 3483.01it/s][01:59:30] Explicit valence for atom # 23 N, 4, is greater than permitted\n",
      "[01:59:30] Explicit valence for atom # 18 N, 4, is greater than permitted\n",
      "[01:59:30] ERROR: Explicit valence for atom # 18 N, 4, is greater than permitted\n",
      "\n",
      " 25%|██▍       | 70002/280242 [00:18<01:04, 3269.46it/s][01:59:30] Explicit valence for atom # 23 O, 3, is greater than permitted\n",
      "[01:59:30] Explicit valence for atom # 44 B, 7, is greater than permitted\n",
      "[01:59:30] ERROR: Explicit valence for atom # 44 B, 7, is greater than permitted\n",
      "\n",
      " 25%|██▌       | 70332/280242 [00:18<01:04, 3265.72it/s][01:59:30] Explicit valence for atom # 7 O, 3, is greater than permitted\n",
      "[01:59:30] Explicit valence for atom # 46 B, 7, is greater than permitted\n",
      "[01:59:30] ERROR: Explicit valence for atom # 46 B, 7, is greater than permitted\n",
      "\n",
      " 25%|██▌       | 70661/280242 [00:18<01:04, 3233.51it/s][01:59:30] Explicit valence for atom # 20 N, 4, is greater than permitted\n",
      "[01:59:30] Explicit valence for atom # 18 N, 4, is greater than permitted\n",
      "[01:59:30] ERROR: Explicit valence for atom # 18 N, 4, is greater than permitted\n",
      "\n",
      " 26%|██▌       | 73038/280242 [00:19<00:53, 3843.00it/s][01:59:31] Explicit valence for atom # 16 O, 3, is greater than permitted\n",
      "[01:59:31] Explicit valence for atom # 24 O, 3, is greater than permitted\n",
      " 26%|██▌       | 73424/280242 [00:19<00:54, 3802.64it/s][01:59:31] Can't kekulize mol.  Unkekulized atoms: 1 4 5 6 7 9 10 11 12 13 14\n",
      "[01:59:31] Explicit valence for atom # 6 N, 4, is greater than permitted\n",
      "[01:59:31] Explicit valence for atom # 20 N, 4, is greater than permitted\n",
      "[01:59:31] ERROR: Explicit valence for atom # 20 N, 4, is greater than permitted\n",
      "\n",
      "[01:59:31] Explicit valence for atom # 3 N, 4, is greater than permitted\n",
      "[01:59:31] Explicit valence for atom # 21 N, 4, is greater than permitted\n",
      "[01:59:31] ERROR: Explicit valence for atom # 21 N, 4, is greater than permitted\n",
      "\n",
      " 27%|██▋       | 74859/280242 [00:19<01:02, 3295.01it/s][01:59:31] Explicit valence for atom # 14 N, 4, is greater than permitted\n",
      "[01:59:31] Explicit valence for atom # 23 N, 4, is greater than permitted\n",
      "[01:59:31] ERROR: Explicit valence for atom # 23 N, 4, is greater than permitted\n",
      "\n",
      "[01:59:31] Explicit valence for atom # 16 N, 4, is greater than permitted\n",
      "[01:59:31] Explicit valence for atom # 22 N, 4, is greater than permitted\n",
      "[01:59:31] ERROR: Explicit valence for atom # 22 N, 4, is greater than permitted\n",
      "\n",
      " 27%|██▋       | 75245/280242 [00:19<00:59, 3451.36it/s][01:59:32] Explicit valence for atom # 8 N, 4, is greater than permitted\n",
      "[01:59:32] Explicit valence for atom # 24 N, 4, is greater than permitted\n",
      "[01:59:32] ERROR: Explicit valence for atom # 24 N, 4, is greater than permitted\n",
      "\n",
      "[01:59:32] Explicit valence for atom # 16 N, 4, is greater than permitted\n",
      "[01:59:32] Explicit valence for atom # 25 N, 4, is greater than permitted\n",
      "[01:59:32] ERROR: Explicit valence for atom # 25 N, 4, is greater than permitted\n",
      "\n",
      "[01:59:32] Explicit valence for atom # 21 N, 4, is greater than permitted\n",
      "[01:59:32] Explicit valence for atom # 22 N, 4, is greater than permitted\n",
      "[01:59:32] ERROR: Explicit valence for atom # 22 N, 4, is greater than permitted\n",
      "\n",
      " 27%|██▋       | 75636/280242 [00:19<00:57, 3581.78it/s][01:59:32] Explicit valence for atom # 4 N, 4, is greater than permitted\n",
      "[01:59:32] Explicit valence for atom # 22 N, 4, is greater than permitted\n",
      "[01:59:32] ERROR: Explicit valence for atom # 22 N, 4, is greater than permitted\n",
      "\n",
      "[01:59:32] Can't kekulize mol.  Unkekulized atoms: 2 3 24\n",
      "[01:59:32] Can't kekulize mol.  Unkekulized atoms: 2 3 25\n",
      "[01:59:32] Explicit valence for atom # 4 N, 4, is greater than permitted\n",
      "[01:59:32] Explicit valence for atom # 22 N, 4, is greater than permitted\n",
      "[01:59:32] ERROR: Explicit valence for atom # 22 N, 4, is greater than permitted\n",
      "\n",
      " 27%|██▋       | 76796/280242 [00:20<00:55, 3691.98it/s][01:59:32] Can't kekulize mol.  Unkekulized atoms: 1 2 12\n",
      "[01:59:32] Explicit valence for atom # 28 N, 4, is greater than permitted\n",
      " 28%|██▊       | 78008/280242 [00:20<00:52, 3853.62it/s][01:59:32] Can't kekulize mol.  Unkekulized atoms: 16 17 23 24 25\n",
      "[01:59:32] Can't kekulize mol.  Unkekulized atoms: 20 21 27 28 29\n",
      "[01:59:32] Can't kekulize mol.  Unkekulized atoms: 16 17 25 26 27\n",
      "[01:59:32] Explicit valence for atom # 28 N, 4, is greater than permitted\n",
      "[01:59:32] Explicit valence for atom # 34 N, 4, is greater than permitted\n",
      "[01:59:32] ERROR: Explicit valence for atom # 34 N, 4, is greater than permitted\n",
      "\n",
      "[01:59:32] Explicit valence for atom # 30 N, 4, is greater than permitted\n",
      "[01:59:32] Explicit valence for atom # 35 N, 4, is greater than permitted\n",
      "[01:59:32] ERROR: Explicit valence for atom # 35 N, 4, is greater than permitted\n",
      "\n",
      "[01:59:32] Can't kekulize mol.  Unkekulized atoms: 2 3 24\n",
      "[01:59:32] Explicit valence for atom # 13 N, 4, is greater than permitted\n",
      "[01:59:32] Explicit valence for atom # 19 N, 4, is greater than permitted\n",
      "[01:59:32] ERROR: Explicit valence for atom # 19 N, 4, is greater than permitted\n",
      "\n",
      "[01:59:32] Explicit valence for atom # 1 N, 4, is greater than permitted\n",
      "[01:59:32] Explicit valence for atom # 15 N, 4, is greater than permitted\n",
      "[01:59:32] ERROR: Explicit valence for atom # 15 N, 4, is greater than permitted\n",
      "\n",
      "[01:59:32] Explicit valence for atom # 1 N, 4, is greater than permitted\n",
      "[01:59:32] Explicit valence for atom # 15 N, 4, is greater than permitted\n",
      "[01:59:32] ERROR: Explicit valence for atom # 15 N, 4, is greater than permitted\n",
      "\n",
      " 28%|██▊       | 78396/280242 [00:20<00:54, 3731.10it/s][01:59:32] Explicit valence for atom # 13 N, 4, is greater than permitted\n",
      "[01:59:32] Explicit valence for atom # 21 N, 4, is greater than permitted\n",
      "[01:59:32] ERROR: Explicit valence for atom # 21 N, 4, is greater than permitted\n",
      "\n",
      "[01:59:32] Explicit valence for atom # 44 O, 3, is greater than permitted\n",
      " 28%|██▊       | 78772/280242 [00:20<00:58, 3442.92it/s][01:59:32] Explicit valence for atom # 26 N, 4, is greater than permitted\n",
      "[01:59:32] Explicit valence for atom # 30 N, 4, is greater than permitted\n",
      "[01:59:32] ERROR: Explicit valence for atom # 30 N, 4, is greater than permitted\n",
      "\n",
      "[01:59:32] Can't kekulize mol.  Unkekulized atoms: 8 9 10 13 14\n",
      "[01:59:32] Explicit valence for atom # 4 N, 4, is greater than permitted\n",
      "[01:59:32] Explicit valence for atom # 4 N, 4, is greater than permitted\n",
      "[01:59:32] Explicit valence for atom # 5 N, 4, is greater than permitted\n",
      "[01:59:32] Explicit valence for atom # 5 N, 4, is greater than permitted\n",
      " 28%|██▊       | 79463/280242 [00:20<01:01, 3243.94it/s][01:59:33] Explicit valence for atom # 22 N, 4, is greater than permitted\n",
      "[01:59:33] Explicit valence for atom # 27 N, 4, is greater than permitted\n",
      "[01:59:33] ERROR: Explicit valence for atom # 27 N, 4, is greater than permitted\n",
      "\n",
      "[01:59:33] Explicit valence for atom # 1 N, 4, is greater than permitted\n",
      "[01:59:33] Explicit valence for atom # 32 N, 4, is greater than permitted\n",
      "[01:59:33] ERROR: Explicit valence for atom # 32 N, 4, is greater than permitted\n",
      "\n",
      " 28%|██▊       | 79791/280242 [00:20<01:04, 3129.35it/s][01:59:33] Can't kekulize mol.  Unkekulized atoms: 7 8 9 10 11\n",
      "[01:59:33] Explicit valence for atom # 20 N, 4, is greater than permitted\n",
      "[01:59:33] Explicit valence for atom # 25 N, 4, is greater than permitted\n",
      "[01:59:33] ERROR: Explicit valence for atom # 25 N, 4, is greater than permitted\n",
      "\n",
      " 29%|██▉       | 81570/280242 [00:21<00:48, 4136.04it/s][01:59:33] Explicit valence for atom # 19 N, 4, is greater than permitted\n",
      "[01:59:33] WARNING:  Problems/mismatches: Mobile-H( Mobile-H groups: Attachment points, Number; Stereobonds/cumulenes: Missing known)\n",
      "\n",
      " 30%|██▉       | 83255/280242 [00:21<00:48, 4046.03it/s][01:59:34] Explicit valence for atom # 34 N, 4, is greater than permitted\n",
      "[01:59:34] WARNING:  Problems/mismatches: Mobile-H( Mobile-H groups: One instead of multiple, Attachment points, Number; Stereobonds/cumulenes: Missing known)\n",
      "\n",
      " 30%|███       | 84103/280242 [00:22<00:47, 4131.40it/s][01:59:34] Explicit valence for atom # 0 P, 11, is greater than permitted\n",
      "[01:59:34] Explicit valence for atom # 58 P, 11, is greater than permitted\n",
      "[01:59:34] ERROR: Explicit valence for atom # 58 P, 11, is greater than permitted\n",
      "\n",
      " 32%|███▏      | 89996/280242 [00:23<00:44, 4243.83it/s][01:59:35] WARNING: not removing hydrogen atom without neighbors\n",
      " 58%|█████▊    | 162056/280242 [00:39<00:25, 4589.76it/s][01:59:51] Explicit valence for atom # 14 C, 5, is greater than permitted\n",
      " 70%|███████   | 196544/280242 [00:46<00:19, 4253.08it/s][01:59:58] Explicit valence for atom # 5 N, 5, is greater than permitted\n",
      " 81%|████████  | 226571/280242 [00:52<00:11, 4676.41it/s][02:00:05] Explicit valence for atom # 9 C, 5, is greater than permitted\n",
      "100%|██████████| 280242/280242 [01:04<00:00, 4354.14it/s]\n"
     ]
    }
   ],
   "source": [
    "from rdkit import Chem\n",
    "\n",
    "def get_canonical_smiles(datum):\n",
    "    \"\"\"\n",
    "    Converts a SMILES string to its canonical form.\n",
    "\n",
    "\n",
    "    Returns:\n",
    "    str: The canonical SMILES string.\n",
    "    \"\"\"\n",
    "    smiles = datum['smiles']\n",
    "    try:\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is None:\n",
    "            raise Exception(\"Invalid SMILES string\")\n",
    "        canonical_smiles = Chem.MolToSmiles(mol, canonical=True)\n",
    "        return canonical_smiles\n",
    "    except:\n",
    "        try:\n",
    "            inchi = datum['inchi']\n",
    "            mol = Chem.MolFromInchi(inchi)\n",
    "            if mol is None:\n",
    "                raise Exception(\"Invalid Inchi string\")\n",
    "            canonical_smiles = Chem.MolToSmiles(mol, canonical=True)\n",
    "            return canonical_smiles\n",
    "        except:\n",
    "            # # print(\"BAD: \", smiles, inchi)\n",
    "            return None\n",
    "canonical_smiles_to_npmrd_id = dict([[get_canonical_smiles(d), d['accession'] ]for d in tqdm.tqdm(data['np_mrd']['natural_product'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only C: 215 | Only H: 0 | Both C and H: 3930\n",
      "118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 4/118 [00:01<00:41,  2.77it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:35<00:00,  3.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only C: 220 | Only H: 0 | Both C and H: 3986\n",
      "126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 126/126 [00:33<00:00,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only C: 1851 | Only H: 0 | Both C and H: 31938\n",
      "1017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [03:31<00:00,  4.80it/s]\n"
     ]
    }
   ],
   "source": [
    "npmrd_id_to_smiles = dict([v,k] for k,v in canonical_smiles_to_npmrd_id.items())\n",
    "\n",
    "dataset_path=  Path('/workspace/SMILES_dataset')\n",
    "\n",
    "for split in ['test', 'val', \"train\"]:\n",
    "\n",
    "    index_to_smiles = pickle.load(open(dataset_path / split / 'SMILES/index.pkl', 'rb'))\n",
    "    smiles_to_index = dict([[v,k] for k,v in index_to_smiles.items()])\n",
    "    path_1d = Path( dataset_path / split)\n",
    "    oneD_NMRs = os.listdir(path_1d/'oneD_NMR')\n",
    "    # look for both empty tensors\n",
    "    only_c, only_h, c_and_h = 0, 0, 0\n",
    "    empty = []\n",
    "    for i in oneD_NMRs:\n",
    "        c_tensor, h_tensor = torch.load(path_1d / 'oneD_NMR'/ i)\n",
    "        if len(c_tensor) > 0 and len(h_tensor) > 0:\n",
    "            c_and_h += 1\n",
    "        elif len(c_tensor) > 0:\n",
    "            only_c += 1\n",
    "        elif len(h_tensor) > 0:\n",
    "            only_h += 1\n",
    "        else:\n",
    "            empty.append(i)\n",
    "            \n",
    "    print(f'Only C: {only_c} | Only H: {only_h} | Both C and H: {c_and_h}')\n",
    "\n",
    "\n",
    "    np_ids_with_empty_tensors = [canonical_smiles_to_npmrd_id[index_to_smiles[int(file_index.split(\".\")[0])]] for file_index in empty]\n",
    "    txt_file_locations = filter(lambda x: x.split(\"_\")[0] in np_ids_with_empty_tensors, npmrd_files_txt_only)\n",
    "\n",
    "    txt_file_locations= list(txt_file_locations)\n",
    "    assert (len(txt_file_locations) == len (empty))\n",
    "    print(len(empty))\n",
    "    \n",
    "    # continue\n",
    "\n",
    "    for txt_f in tqdm.tqdm(txt_file_locations):\n",
    "        smiles = npmrd_id_to_smiles [txt_f.split(\"_\")[0]]\n",
    "        file_index = smiles_to_index[smiles]\n",
    "        save_path = dataset_path / split / 'oneD_NMR' / f\"{file_index}.pt\"\n",
    "        \n",
    "        c_values = set()\n",
    "        h_values = set()\n",
    "        with open(Path(NP_MRD_FILES_dir) / txt_f) as f:\n",
    "            \n",
    "            try:\n",
    "                for line in f:\n",
    "                    parts = line.strip().split('\\t')\n",
    "                    if len(parts) < 3 or not parts[2]:\n",
    "                        continue  # Skip lines that don't have enough parts or the third column is empty\n",
    "\n",
    "                    id, element, value, *_ = parts\n",
    "                    # print(element, value)\n",
    "                    if value in [\"chemical_shift\", \"shift\", \"NA\"]:\n",
    "                        continue\n",
    "                    \n",
    "                    value = float(value)\n",
    "\n",
    "                    if element == 'C':\n",
    "                        c_values.add(value)\n",
    "                    elif element == 'H':\n",
    "                        h_values.add(value)\n",
    "                if len(c_values)==0 and len(h_values)==0:\n",
    "                    print(\"No c and H\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(txt_f)\n",
    "                print(element, value )\n",
    "                print(parts)               \n",
    "                    \n",
    "                raise(e)\n",
    "        c_tensor = torch.tensor(list(c_values), dtype=torch.float32)\n",
    "        h_tensor = torch.tensor(list(h_values), dtype=torch.float32)\n",
    "        torch.save([c_tensor, h_tensor], save_path)\n",
    "        \n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6713"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "file_paths = os.listdir('/workspace/OneD_Only_Dataset/train/oneD_NMR/')\n",
    "len(file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_2 = pickle.load(open('/root/gurusmart/MorganFP_prediction/reproduce_previous_works/smart4.5/out_2.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "a = pickle.load(open('/root/gurusmart/MorganFP_prediction/reproduce_previous_works/smart4.5/notebooks/dataset_building/FP_on_bits_pickles/Exact_FP_on_bits_r0_r15_len_1024_2d_train.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1478.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a[0][34])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 4])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.array([1,2,3,4,5])\n",
    "b = np.array([2,3])\n",
    "a[list(b)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
