{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pickle, sys, torch, numpy as np\n",
    "\n",
    "# paths  \n",
    "# table_path = '/root/gurusmart/MorganFP_prediction/reproduce_previous_works/all_2d1d_datasets/entropy_radius_exps_on_HSQC'\n",
    "# table_path = \"/root/gurusmart/MorganFP_prediction/reproduce_previous_works/entropy_on_hashes/train_on_all_data_possible_with_jittering\"\n",
    "# table_path = \"/root/gurusmart/MorganFP_prediction/reproduce_previous_works/entropy_on_hashes/all_HSQC_jittering_search\"\n",
    "table_path = \"/root/gurusmart/MorganFP_prediction/reproduce_previous_works/entropy_on_hashes/flexible_models_jittering_flexible_MW_flexible_normal_hsqc\"\n",
    "print_keys = [\n",
    "    \"test/mean_rank_1\",\n",
    "    \"test/mean_rank_5\",\n",
    "    \"test/mean_rank_10\",\n",
    "    # \"test/mean_mean_rank\",\n",
    "    \"test/mean_cos\",\n",
    "    # \"test/mean_f1\", \n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first part is for different kinds of NMR in the all info set (kinda depreated now)\n",
    "\n",
    "\n",
    "The second part is for training with all possible data of a specific type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>, {})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "exp_name_to_key_to_results = defaultdict(lambda: defaultdict(list))\n",
    "# for input_type in ['1d', \"all_info\", \"HSQC_and_C\", \"HSQC_and_H\", \"only_C\", \"only_H\", \"only_HSQC\"]:\n",
    "\n",
    "for input_type in ['all_info']:    \n",
    "    # table_path = f'/root/gurusmart/MorganFP_prediction/reproduce_previous_works/puuting_h_in_the_middle/entropy_radius_exps_{input_type}'\n",
    "    # table_path = f'/root/gurusmart/MorganFP_prediction/reproduce_previous_works/rank_on_entire_set/entropy_radius_exps_{input_type}'\n",
    "\n",
    "\n",
    "    all_exps = os.listdir(table_path)\n",
    "    # load pickles \n",
    "    for exp in all_exps:\n",
    "        if 'trial' in exp:\n",
    "            trial_spelling = \"trial\"\n",
    "        elif 'trail' in exp:\n",
    "            trial_spelling = \"trail\"\n",
    "           \n",
    "        try:     \n",
    "            # print(exp)\n",
    "            with open(f'{table_path}/{exp}/test_result.pkl', 'rb') as f:\n",
    "                result = pickle.load(f)[0]\n",
    "                \n",
    "                for key in print_keys:\n",
    "                    if key not in result:\n",
    "                        continue\n",
    "                    exp_name_to_key_to_results[\"_\".join(exp.split(trial_spelling)[:-1])][key].append(result[key])\n",
    "                    # exp_name_to_key_to_results[exp][key].append(result[key])\n",
    "                    # print(key, result[key])\n",
    "        except Exception as e:\n",
    "            print(f'{table_path}/{exp}/test_result.pkl')            \n",
    "    \n",
    "exp_name_to_key_to_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # compute the std  of rank_1 and rank_5 for each nmr\n",
    "# for exp_name, key_to_results in exp_name_to_key_to_results.items():\n",
    "#     for key, results in key_to_results.items():\n",
    "#         if key in [\"test/mean_rank_1\", \"test/mean_rank_5\"]:\n",
    "#             print(exp_name, key, np.mean(results), np.std(results))\n",
    "#         # print(exp_name, key, np.mean(results), np.std(results))\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "avg_results = {}\n",
    "for exp_name, key_to_results in exp_name_to_key_to_results.items():\n",
    "    avg_results[exp_name] = {key:[ np.mean(val), np.std(val) ]for key, val in key_to_results.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort based on dict key \n",
    "def get_sort_key(item):\n",
    "    if ((item[0].split(\"R0_to_R\")[-1]).split(\"_\")[0]).isdecimal():\n",
    "        return int((item[0].split(\"R0_to_R\")[-1]).split(\"_\")[0])\n",
    "    \n",
    "    else:\n",
    "        return float('inf')\n",
    "\n",
    "\n",
    "\n",
    "avg_results = dict(sorted(avg_results.items(),key=get_sort_key ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'only_hsqc_jittering_0.5-': {'test/mean_cos': [np.float64(0.894456704457601),\n",
       "   np.float64(0.0007555056193796932)]},\n",
       " 'only_hsqc_jittering_0.25-': {'test/mean_cos': [np.float64(0.8996819257736206),\n",
       "   np.float64(0.0006018465838946809)]},\n",
       " 'only_hsqc_jittering_2-': {'test/mean_cos': [np.float64(0.8579060633977255),\n",
       "   np.float64(0.0017887863103610742)]},\n",
       " 'only_hsqc_jittering_0-': {'test/mean_cos': [np.float64(0.9033106168111166),\n",
       "   np.float64(0.001545167133996608)]},\n",
       " 'only_hsqc_jittering_1-': {'test/mean_cos': [np.float64(0.8851240277290344),\n",
       "   np.float64(0.0018626676297420661)]}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 3 NMRs \\\\\n",
      "\\hline\n",
      "13C and 1H \\\\\n",
      "\\hline\n",
      "HSQC and 13C \\\\\n",
      "\\hline\n",
      "HSQC and 1H \\\\\n",
      "\\hline\n",
      "Only 13C \\\\\n",
      "\\hline\n",
      "Only 1H \\\\\n",
      "\\hline\n",
      "Only HSQC \\\\\n",
      "\\hline\n"
     ]
    }
   ],
   "source": [
    "name_convert = {\n",
    "    \"all_info\": \"All 3 NMRs\",\n",
    "    \"1d\": \"13C and 1H\",\n",
    "    \"HSQC_and_C\": \"HSQC and 13C\",\n",
    "    \"HSQC_and_H\": \"HSQC and 1H\",\n",
    "    \"only_c\": \"Only 13C\",\n",
    "    \"only_H\": \"Only 1H\",\n",
    "    \"only_hsqc\": \"Only HSQC\",\n",
    "}\n",
    "\n",
    "# for each combination, find which fp is best\n",
    "for combination in [\"all_info\", '1d', \"HSQC_and_C\", \"HSQC_and_H\", \"only_c\", \"only_H\", \"only_hsqc\"]:\n",
    "    print(name_convert[combination], end=\"\")\n",
    "    for mfp_type in [\"R0_to_R1_\", \"R0_to_R2\", \"R0_to_R3\", \"R0_to_R4\", \"R0_to_R5\", \"Hyun_FP\"]:\n",
    "        for key, metric_dict in avg_results.items():\n",
    "            # print(key)\n",
    "            if combination not in key or mfp_type not in key:\n",
    "                continue\n",
    "            for metric, (mean,std) in metric_dict.items():\n",
    "                if metric in [\"test/mean_rank_1\", ]:\n",
    "                    print(f' & {mean*100:.1f}\\%\\\\textpm{std*100:.1f}\\%', end=\"\")\n",
    "    print(\" \\\\\\\\\")\n",
    "    print(\"\\hline\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\\begin{table}[h]\n",
      "\\centering\n",
      "\\resizebox{\\textwidth}{!}{\n",
      "\\begin{tabular}{|c|c|c|c|c|c|}\n",
      "\\hline\n",
      "Model Input & Rank-1$\\uparrow$ & Rank-5$\\uparrow$ & Mean Rank$\\downarrow$ & Cosine Sim$\\uparrow$ & F1-score$\\uparrow$\\\\\n",
      "\\hline\n",
      "\\end{tabular}\n",
      "}\n",
      "\\caption{Performance of various MFs when All 3 NMRs is available}\n",
      "\\label{table_name}\n",
      "\\end{table}\n",
      "\n",
      "\n",
      "\n",
      "\\begin{table}[h]\n",
      "\\centering\n",
      "\\resizebox{\\textwidth}{!}{\n",
      "\\begin{tabular}{|c|c|c|c|c|c|}\n",
      "\\hline\n",
      "Model Input & Rank-1$\\uparrow$ & Rank-5$\\uparrow$ & Mean Rank$\\downarrow$ & Cosine Sim$\\uparrow$ & F1-score$\\uparrow$\\\\\n",
      "\\hline\n",
      "\\end{tabular}\n",
      "}\n",
      "\\caption{Performance of various MFs when 13C and 1H is available}\n",
      "\\label{table_name}\n",
      "\\end{table}\n",
      "\n",
      "\n",
      "\n",
      "\\begin{table}[h]\n",
      "\\centering\n",
      "\\resizebox{\\textwidth}{!}{\n",
      "\\begin{tabular}{|c|c|c|c|c|c|}\n",
      "\\hline\n",
      "Model Input & Rank-1$\\uparrow$ & Rank-5$\\uparrow$ & Mean Rank$\\downarrow$ & Cosine Sim$\\uparrow$ & F1-score$\\uparrow$\\\\\n",
      "\\hline\n",
      "\\end{tabular}\n",
      "}\n",
      "\\caption{Performance of various MFs when HSQC and 13C is available}\n",
      "\\label{table_name}\n",
      "\\end{table}\n",
      "\n",
      "\n",
      "\n",
      "\\begin{table}[h]\n",
      "\\centering\n",
      "\\resizebox{\\textwidth}{!}{\n",
      "\\begin{tabular}{|c|c|c|c|c|c|}\n",
      "\\hline\n",
      "Model Input & Rank-1$\\uparrow$ & Rank-5$\\uparrow$ & Mean Rank$\\downarrow$ & Cosine Sim$\\uparrow$ & F1-score$\\uparrow$\\\\\n",
      "\\hline\n",
      "\\end{tabular}\n",
      "}\n",
      "\\caption{Performance of various MFs when HSQC and 1H is available}\n",
      "\\label{table_name}\n",
      "\\end{table}\n",
      "\n",
      "\n",
      "\n",
      "\\begin{table}[h]\n",
      "\\centering\n",
      "\\resizebox{\\textwidth}{!}{\n",
      "\\begin{tabular}{|c|c|c|c|c|c|}\n",
      "\\hline\n",
      "Model Input & Rank-1$\\uparrow$ & Rank-5$\\uparrow$ & Mean Rank$\\downarrow$ & Cosine Sim$\\uparrow$ & F1-score$\\uparrow$\\\\\n",
      "\\hline\n",
      "\\end{tabular}\n",
      "}\n",
      "\\caption{Performance of various MFs when Only 13C is available}\n",
      "\\label{table_name}\n",
      "\\end{table}\n",
      "\n",
      "\n",
      "\n",
      "\\begin{table}[h]\n",
      "\\centering\n",
      "\\resizebox{\\textwidth}{!}{\n",
      "\\begin{tabular}{|c|c|c|c|c|c|}\n",
      "\\hline\n",
      "Model Input & Rank-1$\\uparrow$ & Rank-5$\\uparrow$ & Mean Rank$\\downarrow$ & Cosine Sim$\\uparrow$ & F1-score$\\uparrow$\\\\\n",
      "\\hline\n",
      "\\end{tabular}\n",
      "}\n",
      "\\caption{Performance of various MFs when Only 1H is available}\n",
      "\\label{table_name}\n",
      "\\end{table}\n",
      "\n",
      "\n",
      "\n",
      "\\begin{table}[h]\n",
      "\\centering\n",
      "\\resizebox{\\textwidth}{!}{\n",
      "\\begin{tabular}{|c|c|c|c|c|c|}\n",
      "\\hline\n",
      "Model Input & Rank-1$\\uparrow$ & Rank-5$\\uparrow$ & Mean Rank$\\downarrow$ & Cosine Sim$\\uparrow$ & F1-score$\\uparrow$\\\\\n",
      "\\hline\n",
      "\\end{tabular}\n",
      "}\n",
      "\\caption{Performance of various MFs when Only HSQC is available}\n",
      "\\label{table_name}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "for input_type in [\"all_info\", '1d', \"HSQC_and_C\", \"HSQC_and_H\", \"only_c\", \"only_H\", \"only_hsqc\"]:\n",
    "    print(\"\\n\\n\")\n",
    "    # print in latex format\n",
    "    print (\"\\\\begin{table}[h]\")\n",
    "    print(\"\\centering\")\n",
    "    print(\"\\\\resizebox{\\\\textwidth}{!}{\")\n",
    "    print('\\\\begin{tabular}{|c|c|c|c|c|c|}')\n",
    "    print(\"\\hline\")\n",
    "    print(\"Model Input & Rank-1$\\\\uparrow$ & Rank-5$\\\\uparrow$ & Mean Rank$\\\\downarrow$ & Cosine Sim$\\\\uparrow$ & F1-score$\\\\uparrow$\\\\\\\\\")\n",
    "    print(\"\\hline\")\n",
    "\n",
    "    for exp_name, key_to_results in avg_results.items():\n",
    "        if input_type not in exp_name:\n",
    "            continue\n",
    "        \n",
    "        name = exp_name\n",
    "        if name[:2]==\"FP\":\n",
    "            name = \"R\"+name.split(\" \")[-1][-2]+\" FP\"\n",
    "        MF_name = \" \".join(name.split(\"_\")[:3]) + \" MF\"\n",
    "        if MF_name.startswith(\"Hyun\"):\n",
    "            MF_name = \"DeepSAT FP\"\n",
    "        print(MF_name, end=\"\")\n",
    "        for key, (mean, std) in key_to_results.items():\n",
    "            if key in [\"test/mean_rank_1\", \"test/mean_rank_5\"]:\n",
    "                print(f' & {mean*100:.2f}\\%\\\\textpm{std*100:.2f}\\%', end=\"\")\n",
    "            elif key in [\"test/mean_mean_rank\"]:\n",
    "                print(f' & {mean+1:.2f}\\\\textpm{std:.2f}', end=\"\")\n",
    "            else:\n",
    "                print(f' & {mean:.4f}\\\\textpm{std:.4f}', end=\"\")\n",
    "        print(\" \\\\\\\\\")\n",
    "        print(\"\\hline\")\n",
    "        \n",
    "    print('\\end{tabular}')\n",
    "    print('}')\n",
    "    print(\"\\caption{Performance of various MFs when \"+ name_convert[input_type] +\" is available}\")\n",
    "    print('\\label{table_name}')\n",
    "    print('\\end{table}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'exp_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mexp_name\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'exp_name' is not defined"
     ]
    }
   ],
   "source": [
    "exp_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All_possible_data speciliazed, WITHOUT MW\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {'no_mw_only_c_': defaultdict(list,\n",
       "                         {'test/mean_cos': [0.8228265047073364,\n",
       "                           0.8244693875312805,\n",
       "                           0.8221435546875],\n",
       "                          'test/mean_f1': [0.8479827642440796,\n",
       "                           0.8496001958847046,\n",
       "                           0.8477576375007629]}),\n",
       "             'no_mw_all_info_': defaultdict(list,\n",
       "                         {'test/mean_cos': [0.8522774577140808,\n",
       "                           0.8559113144874573,\n",
       "                           0.8575615882873535],\n",
       "                          'test/mean_f1': [0.867366373538971,\n",
       "                           0.8711423873901367,\n",
       "                           0.8719686269760132]}),\n",
       "             'no_mw_normal_HSQC_and_H_': defaultdict(list,\n",
       "                         {'test/mean_cos': [0.8121713399887085,\n",
       "                           0.8144845366477966,\n",
       "                           0.8162031769752502],\n",
       "                          'test/mean_f1': [0.8330954313278198,\n",
       "                           0.8361547589302063,\n",
       "                           0.8375082612037659]}),\n",
       "             'no_mw_all_info_normal_HSQC_': defaultdict(list,\n",
       "                         {'test/mean_cos': [0.8495339155197144,\n",
       "                           0.8460635542869568,\n",
       "                           0.8454698920249939],\n",
       "                          'test/mean_f1': [0.8663629293441772,\n",
       "                           0.8628384470939636,\n",
       "                           0.8622621297836304]}),\n",
       "             'no_mw_normal_HSQC_and_C_': defaultdict(list,\n",
       "                         {'test/mean_cos': [0.8495339155197144,\n",
       "                           0.8462870717048645,\n",
       "                           0.8460635542869568],\n",
       "                          'test/mean_f1': [0.8663629293441772,\n",
       "                           0.8631969690322876,\n",
       "                           0.8628384470939636]}),\n",
       "             'no_mw_only_h_': defaultdict(list,\n",
       "                         {'test/mean_cos': [0.597780704498291,\n",
       "                           0.5984242558479309,\n",
       "                           0.60149085521698],\n",
       "                          'test/mean_f1': [0.6139180064201355,\n",
       "                           0.6130638122558594,\n",
       "                           0.6180894374847412]}),\n",
       "             'no_mw_only_hsqc_': defaultdict(list,\n",
       "                         {'test/mean_cos': [0.8575615882873535,\n",
       "                           0.8764320015907288,\n",
       "                           0.8536450266838074],\n",
       "                          'test/mean_f1': [0.8719686269760132,\n",
       "                           0.8935052752494812,\n",
       "                           0.8685613870620728]}),\n",
       "             'no_mw_HSQC_and_C_': defaultdict(list,\n",
       "                         {'test/mean_cos': [0.8555591702461243,\n",
       "                           0.8536450266838074,\n",
       "                           0.8575615882873535],\n",
       "                          'test/mean_f1': [0.8707711696624756,\n",
       "                           0.8685613870620728,\n",
       "                           0.8719686269760132]}),\n",
       "             'no_mw_only_normal_hsqc_': defaultdict(list,\n",
       "                         {'test/mean_cos': [0.8495339155197144,\n",
       "                           0.8454638719558716,\n",
       "                           0.8460635542869568],\n",
       "                          'test/mean_f1': [0.8663629293441772,\n",
       "                           0.8627691864967346,\n",
       "                           0.8628384470939636]}),\n",
       "             'no_mw_HSQC_and_H_': defaultdict(list,\n",
       "                         {'test/mean_cos': [0.8323415517807007,\n",
       "                           0.8344486951828003,\n",
       "                           0.8051571249961853],\n",
       "                          'test/mean_f1': [0.8512096405029297,\n",
       "                           0.8527225852012634,\n",
       "                           0.8231555223464966]}),\n",
       "             'no_mw_only_1d_': defaultdict(list,\n",
       "                         {'test/mean_cos': [0.8454245924949646,\n",
       "                           0.84591144323349,\n",
       "                           0.8462502360343933],\n",
       "                          'test/mean_f1': [0.864855170249939,\n",
       "                           0.8647316098213196,\n",
       "                           0.8650561571121216]})})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_keys = [\n",
    "    # \"test/mean_rank_1\",\n",
    "    # \"test/mean_rank_5\",\n",
    "    # \"test/mean_rank_10\",\n",
    "    # \"test/mean_mean_rank\",\n",
    "    \"test/mean_cos\",\n",
    "    \"test/mean_f1\", \n",
    "]\n",
    "\n",
    "import os, pickle, sys, torch, numpy as np\n",
    "\n",
    "from collections import defaultdict\n",
    "exp_name_to_key_to_results = defaultdict(lambda: defaultdict(list))\n",
    "# for input_type in ['1d', \"all_info\", \"HSQC_and_C\", \"HSQC_and_H\", \"only_C\", \"only_H\", \"only_HSQC\"]:\n",
    "for input_type in ['']:    \n",
    "    # table_path = f'/root/gurusmart/MorganFP_prediction/reproduce_previous_works/stop_on_cosine/all_data_possible'\n",
    "    # table_path = \"/root/gurusmart/MorganFP_prediction/reproduce_previous_works/rank_on_entire_set/all_data_possible\"\n",
    "    table_path = \"/root/gurusmart/MorganFP_prediction/reproduce_previous_works/entropy_on_hashes/train_on_all_data_possible_with_jittering\"\n",
    "    table_path = \"/root/gurusmart/MorganFP_prediction/reproduce_previous_works/more_specialized_models/train_on_all_data_possible_with_jittering\"\n",
    "\n",
    "\n",
    "    all_exps = os.listdir(table_path)\n",
    "    # load pickles \n",
    "    for exp in all_exps:\n",
    "        if 'trial' in exp:\n",
    "            trial_spelling = \"trial\"\n",
    "        elif 'trail' in exp:\n",
    "            trial_spelling = \"trail\"\n",
    "           \n",
    "        if \"no_mw\" not in exp:\n",
    "            continue\n",
    "        try:     \n",
    "            # print(exp)\n",
    "            with open(f'{table_path}/{exp}/test_result.pkl', 'rb') as f:\n",
    "                result = pickle.load(f)[0]\n",
    "                \n",
    "                for key in print_keys:\n",
    "                    if key not in result:\n",
    "                        continue\n",
    "                    exp_name_to_key_to_results[\"_\".join(exp.split(trial_spelling)[:-1])][key].append(result[key])\n",
    "                    # exp_name_to_key_to_results[exp][key].append(result[key])\n",
    "                    # print(key, result[key])\n",
    "        except Exception as e:\n",
    "            print(f'{table_path}/{exp}/test_result.pkl')            \n",
    "    \n",
    "exp_name_to_key_to_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_results = {}\n",
    "std_results = {}\n",
    "for exp_name, key_to_results in exp_name_to_key_to_results.items():\n",
    "    if \"no_mw\" in exp_name:\n",
    "        avg_results[exp_name] = {key: (round(np.mean(val),4), round(np.std(val),4)) for key, val in key_to_results.items() }\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['no_mw_only_c_', 'no_mw_all_info_', 'no_mw_normal_HSQC_and_H_', 'no_mw_all_info_normal_HSQC_', 'no_mw_normal_HSQC_and_C_', 'no_mw_only_h_', 'no_mw_only_hsqc_', 'no_mw_HSQC_and_C_', 'no_mw_only_normal_hsqc_', 'no_mw_HSQC_and_H_', 'no_mw_only_1d_'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'no_mw_only_c_': {'test/mean_cos': (np.float64(0.8231), np.float64(0.001)),\n",
       "  'test/mean_f1': (np.float64(0.8484), np.float64(0.0008))},\n",
       " 'no_mw_all_info_': {'test/mean_cos': (np.float64(0.8553), np.float64(0.0022)),\n",
       "  'test/mean_f1': (np.float64(0.8702), np.float64(0.002))},\n",
       " 'no_mw_normal_HSQC_and_H_': {'test/mean_cos': (np.float64(0.8143),\n",
       "   np.float64(0.0017)),\n",
       "  'test/mean_f1': (np.float64(0.8356), np.float64(0.0018))},\n",
       " 'no_mw_all_info_normal_HSQC_': {'test/mean_cos': (np.float64(0.847),\n",
       "   np.float64(0.0018)),\n",
       "  'test/mean_f1': (np.float64(0.8638), np.float64(0.0018))},\n",
       " 'no_mw_normal_HSQC_and_C_': {'test/mean_cos': (np.float64(0.8473),\n",
       "   np.float64(0.0016)),\n",
       "  'test/mean_f1': (np.float64(0.8641), np.float64(0.0016))},\n",
       " 'no_mw_only_h_': {'test/mean_cos': (np.float64(0.5992), np.float64(0.0016)),\n",
       "  'test/mean_f1': (np.float64(0.615), np.float64(0.0022))},\n",
       " 'no_mw_only_hsqc_': {'test/mean_cos': (np.float64(0.8625),\n",
       "   np.float64(0.0099)),\n",
       "  'test/mean_f1': (np.float64(0.878), np.float64(0.011))},\n",
       " 'no_mw_HSQC_and_C_': {'test/mean_cos': (np.float64(0.8556),\n",
       "   np.float64(0.0016)),\n",
       "  'test/mean_f1': (np.float64(0.8704), np.float64(0.0014))},\n",
       " 'no_mw_only_normal_hsqc_': {'test/mean_cos': (np.float64(0.847),\n",
       "   np.float64(0.0018)),\n",
       "  'test/mean_f1': (np.float64(0.864), np.float64(0.0017))},\n",
       " 'no_mw_HSQC_and_H_': {'test/mean_cos': (np.float64(0.824),\n",
       "   np.float64(0.0133)),\n",
       "  'test/mean_f1': (np.float64(0.8424), np.float64(0.0136))},\n",
       " 'no_mw_only_1d_': {'test/mean_cos': (np.float64(0.8459), np.float64(0.0003)),\n",
       "  'test/mean_f1': (np.float64(0.8649), np.float64(0.0001))}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no_mw_only_c_\n",
      "test/mean_cos:  {'mean': np.float64(0.8231), 'std': np.float64(0.001)}\n",
      "test/mean_f1:  {'mean': np.float64(0.8484), 'std': np.float64(0.0008)}\n",
      "\n",
      "no_mw_all_info_\n",
      "test/mean_cos:  {'mean': np.float64(0.8553), 'std': np.float64(0.0022)}\n",
      "test/mean_f1:  {'mean': np.float64(0.8702), 'std': np.float64(0.002)}\n",
      "\n",
      "no_mw_normal_HSQC_and_H_\n",
      "test/mean_cos:  {'mean': np.float64(0.8143), 'std': np.float64(0.0017)}\n",
      "test/mean_f1:  {'mean': np.float64(0.8356), 'std': np.float64(0.0018)}\n",
      "\n",
      "no_mw_all_info_normal_HSQC_\n",
      "test/mean_cos:  {'mean': np.float64(0.847), 'std': np.float64(0.0018)}\n",
      "test/mean_f1:  {'mean': np.float64(0.8638), 'std': np.float64(0.0018)}\n",
      "\n",
      "no_mw_normal_HSQC_and_C_\n",
      "test/mean_cos:  {'mean': np.float64(0.8473), 'std': np.float64(0.0016)}\n",
      "test/mean_f1:  {'mean': np.float64(0.8641), 'std': np.float64(0.0016)}\n",
      "\n",
      "no_mw_only_h_\n",
      "test/mean_cos:  {'mean': np.float64(0.5992), 'std': np.float64(0.0016)}\n",
      "test/mean_f1:  {'mean': np.float64(0.615), 'std': np.float64(0.0022)}\n",
      "\n",
      "no_mw_only_hsqc_\n",
      "test/mean_cos:  {'mean': np.float64(0.8625), 'std': np.float64(0.0099)}\n",
      "test/mean_f1:  {'mean': np.float64(0.878), 'std': np.float64(0.011)}\n",
      "\n",
      "no_mw_HSQC_and_C_\n",
      "test/mean_cos:  {'mean': np.float64(0.8556), 'std': np.float64(0.0016)}\n",
      "test/mean_f1:  {'mean': np.float64(0.8704), 'std': np.float64(0.0014)}\n",
      "\n",
      "no_mw_only_normal_hsqc_\n",
      "test/mean_cos:  {'mean': np.float64(0.847), 'std': np.float64(0.0018)}\n",
      "test/mean_f1:  {'mean': np.float64(0.864), 'std': np.float64(0.0017)}\n",
      "\n",
      "no_mw_HSQC_and_H_\n",
      "test/mean_cos:  {'mean': np.float64(0.824), 'std': np.float64(0.0133)}\n",
      "test/mean_f1:  {'mean': np.float64(0.8424), 'std': np.float64(0.0136)}\n",
      "\n",
      "no_mw_only_1d_\n",
      "test/mean_cos:  {'mean': np.float64(0.8459), 'std': np.float64(0.0003)}\n",
      "test/mean_f1:  {'mean': np.float64(0.8649), 'std': np.float64(0.0001)}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k,v in avg_results.items():\n",
    "    print(k)\n",
    "    for key, (mean, std) in v.items():\n",
    "       \n",
    "            print(f'{key}: ', {'mean': mean, 'std': std})\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specialized. With MW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/gurusmart/MorganFP_prediction/reproduce_previous_works/entropy_on_hashes/train_on_all_data_possible_with_jittering/retest/test_result.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {'only_hsqc_': defaultdict(list,\n",
       "                         {'test/mean_cos': [0.8734697103500366,\n",
       "                           0.869910717010498,\n",
       "                           0.8707316517829895],\n",
       "                          'test/mean_f1': [0.8886680006980896,\n",
       "                           0.8857546448707581,\n",
       "                           0.8854956030845642]}),\n",
       "             'only_1d_': defaultdict(list,\n",
       "                         {'test/mean_cos': [0.8384703397750854,\n",
       "                           0.8388356566429138,\n",
       "                           0.8364813327789307],\n",
       "                          'test/mean_f1': [0.856576681137085,\n",
       "                           0.8567399978637695,\n",
       "                           0.8551924824714661]}),\n",
       "             'HSQC_and_C_': defaultdict(list,\n",
       "                         {'test/mean_cos': [0.8477694988250732,\n",
       "                           0.8467238545417786,\n",
       "                           0.8510643243789673],\n",
       "                          'test/mean_f1': [0.8624613881111145,\n",
       "                           0.8611229658126831,\n",
       "                           0.8652541637420654]}),\n",
       "             'only_c_': defaultdict(list,\n",
       "                         {'test/mean_cos': [0.8152887225151062,\n",
       "                           0.8196642398834229,\n",
       "                           0.8239424228668213],\n",
       "                          'test/mean_f1': [0.8373541235923767,\n",
       "                           0.8421360850334167,\n",
       "                           0.8460112810134888]}),\n",
       "             'HSQC_and_H_': defaultdict(list,\n",
       "                         {'test/mean_cos': [0.821654200553894,\n",
       "                           0.8245506882667542,\n",
       "                           0.8214147686958313],\n",
       "                          'test/mean_f1': [0.8391531109809875,\n",
       "                           0.8427922129631042,\n",
       "                           0.8392250537872314]}),\n",
       "             'only_normal_hsqc_': defaultdict(list,\n",
       "                         {'test/mean_cos': [0.8685335516929626,\n",
       "                           0.8690130114555359,\n",
       "                           0.8651826977729797],\n",
       "                          'test/mean_f1': [0.8865265250205994,\n",
       "                           0.8868856430053711,\n",
       "                           0.8837109208106995]}),\n",
       "             'normal_HSQC_and_H_': defaultdict(list,\n",
       "                         {'test/mean_cos': [0.8228235840797424,\n",
       "                           0.8193864822387695,\n",
       "                           0.8221585750579834],\n",
       "                          'test/mean_f1': [0.8423036932945251,\n",
       "                           0.8393492698669434,\n",
       "                           0.8417549729347229]}),\n",
       "             'all_info_normal_HSQC_': defaultdict(list,\n",
       "                         {'test/mean_cos': [0.8457145094871521,\n",
       "                           0.8443968892097473,\n",
       "                           0.8442649841308594],\n",
       "                          'test/mean_f1': [0.8618179559707642,\n",
       "                           0.8611379265785217,\n",
       "                           0.8608233332633972]}),\n",
       "             'only_h_': defaultdict(list,\n",
       "                         {'test/mean_cos': [0.6249470114707947,\n",
       "                           0.6343064904212952,\n",
       "                           0.625605046749115],\n",
       "                          'test/mean_f1': [0.6378257870674133,\n",
       "                           0.6512627601623535,\n",
       "                           0.6390949487686157]}),\n",
       "             'all_info_': defaultdict(list,\n",
       "                         {'test/mean_cos': [0.8417946100234985,\n",
       "                           0.8461004495620728,\n",
       "                           0.8430031538009644],\n",
       "                          'test/mean_f1': [0.8573663234710693,\n",
       "                           0.8614058494567871,\n",
       "                           0.8585069179534912]}),\n",
       "             'normal_HSQC_and_C_': defaultdict(list,\n",
       "                         {'test/mean_cos': [0.8544396162033081,\n",
       "                           0.845385730266571,\n",
       "                           0.8512506484985352],\n",
       "                          'test/mean_f1': [0.8700090646743774,\n",
       "                           0.8616774082183838,\n",
       "                           0.8678009510040283]})})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_keys = [\n",
    "    # \"test/mean_rank_1\",\n",
    "    # \"test/mean_rank_5\",\n",
    "    # \"test/mean_rank_10\",\n",
    "    # \"test/mean_mean_rank\",\n",
    "    \"test/mean_cos\",\n",
    "    \"test/mean_f1\", \n",
    "]\n",
    "\n",
    "import os, pickle, sys, torch, numpy as np\n",
    "\n",
    "from collections import defaultdict\n",
    "exp_name_to_key_to_results = defaultdict(lambda: defaultdict(list))\n",
    "# for input_type in ['1d', \"all_info\", \"HSQC_and_C\", \"HSQC_and_H\", \"only_C\", \"only_H\", \"only_HSQC\"]:\n",
    "for input_type in ['']:    \n",
    "    # table_path = f'/root/gurusmart/MorganFP_prediction/reproduce_previous_works/stop_on_cosine/all_data_possible'\n",
    "    # table_path = \"/root/gurusmart/MorganFP_prediction/reproduce_previous_works/rank_on_entire_set/all_data_possible\"\n",
    "    table_path = \"/root/gurusmart/MorganFP_prediction/reproduce_previous_works/entropy_on_hashes/train_on_all_data_possible_with_jittering\"\n",
    "    # table_path = \"/root/gurusmart/MorganFP_prediction/reproduce_previous_works/more_specialized_models/train_on_all_data_possible_with_jittering\"\n",
    "\n",
    "\n",
    "    all_exps = os.listdir(table_path)\n",
    "    # load pickles \n",
    "    for exp in all_exps:\n",
    "        if 'trial' in exp:\n",
    "            trial_spelling = \"trial\"\n",
    "        elif 'trail' in exp:\n",
    "            trial_spelling = \"trail\"\n",
    "           \n",
    "        if \"no_mw\"  in exp:\n",
    "            continue\n",
    "        try:     \n",
    "            # print(exp)\n",
    "            with open(f'{table_path}/{exp}/test_result.pkl', 'rb') as f:\n",
    "                result = pickle.load(f)[0]\n",
    "                \n",
    "                for key in print_keys:\n",
    "                    if key not in result:\n",
    "                        continue\n",
    "                    exp_name_to_key_to_results[\"_\".join(exp.split(trial_spelling)[:-1])][key].append(result[key])\n",
    "                    # exp_name_to_key_to_results[exp][key].append(result[key])\n",
    "                    # print(key, result[key])\n",
    "        except Exception as e:\n",
    "            print(f'{table_path}/{exp}/test_result.pkl')            \n",
    "    \n",
    "exp_name_to_key_to_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'only_hsqc_': {'test/mean_cos': (np.float64(0.8714), np.float64(0.0015)),\n",
       "  'test/mean_f1': (np.float64(0.8866), np.float64(0.0014))},\n",
       " 'only_1d_': {'test/mean_cos': (np.float64(0.8379), np.float64(0.001)),\n",
       "  'test/mean_f1': (np.float64(0.8562), np.float64(0.0007))},\n",
       " 'HSQC_and_C_': {'test/mean_cos': (np.float64(0.8485), np.float64(0.0018)),\n",
       "  'test/mean_f1': (np.float64(0.8629), np.float64(0.0017))},\n",
       " 'only_c_': {'test/mean_cos': (np.float64(0.8196), np.float64(0.0035)),\n",
       "  'test/mean_f1': (np.float64(0.8418), np.float64(0.0035))},\n",
       " 'HSQC_and_H_': {'test/mean_cos': (np.float64(0.8225), np.float64(0.0014)),\n",
       "  'test/mean_f1': (np.float64(0.8404), np.float64(0.0017))},\n",
       " 'only_normal_hsqc_': {'test/mean_cos': (np.float64(0.8676),\n",
       "   np.float64(0.0017)),\n",
       "  'test/mean_f1': (np.float64(0.8857), np.float64(0.0014))},\n",
       " 'normal_HSQC_and_H_': {'test/mean_cos': (np.float64(0.8215),\n",
       "   np.float64(0.0015)),\n",
       "  'test/mean_f1': (np.float64(0.8411), np.float64(0.0013))},\n",
       " 'all_info_normal_HSQC_': {'test/mean_cos': (np.float64(0.8448),\n",
       "   np.float64(0.0007)),\n",
       "  'test/mean_f1': (np.float64(0.8613), np.float64(0.0004))},\n",
       " 'only_h_': {'test/mean_cos': (np.float64(0.6283), np.float64(0.0043)),\n",
       "  'test/mean_f1': (np.float64(0.6427), np.float64(0.0061))},\n",
       " 'all_info_': {'test/mean_cos': (np.float64(0.8436), np.float64(0.0018)),\n",
       "  'test/mean_f1': (np.float64(0.8591), np.float64(0.0017))},\n",
       " 'normal_HSQC_and_C_': {'test/mean_cos': (np.float64(0.8504),\n",
       "   np.float64(0.0037)),\n",
       "  'test/mean_f1': (np.float64(0.8665), np.float64(0.0035))}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_results = {}\n",
    "std_results = {}\n",
    "for exp_name, key_to_results in exp_name_to_key_to_results.items():\n",
    "    avg_results[exp_name] = {key: (round(np.mean(val),4), round(np.std(val),4)) for key, val in key_to_results.items() }\n",
    "    \n",
    "avg_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get the validation cosine score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jittering 0.0: Mean = 0.9025, Std = 0.0009\n",
      "Jittering 0.25: Mean = 0.8981, Std = 0.0023\n",
      "Jittering 0.5: Mean = 0.8954, Std = 0.0008\n",
      "Jittering 1.0: Mean = 0.8856, Std = 0.0003\n",
      "Jittering 2.0: Mean = 0.8616, Std = 0.0013\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "base_dir = \"/root/gurusmart/MorganFP_prediction/reproduce_previous_works/entropy_on_hashes/all_HSQC_jittering_search\"\n",
    "pattern = re.compile(r'only_hsqc_jittering_([0-9.]+)-trial-\\d+')\n",
    "\n",
    "# Dictionary to collect scores for each jittering value\n",
    "jittering_scores = defaultdict(list)\n",
    "\n",
    "for subfolder in os.listdir(base_dir):\n",
    "    match = pattern.match(subfolder)\n",
    "    if match:\n",
    "        jittering_val = float(match.group(1))\n",
    "        log_path = os.path.join(base_dir, subfolder, \"logs.txt\")\n",
    "        if os.path.isfile(log_path):\n",
    "            with open(log_path, 'r') as f:\n",
    "                for line in f:\n",
    "                    if \"best score:\" in line:\n",
    "                        try:\n",
    "                            score = float(line.strip().split(\"best score:\")[-1])\n",
    "                            jittering_scores[jittering_val].append(score)\n",
    "                        except ValueError:\n",
    "                            print(f\"Could not parse score in {log_path}\")\n",
    "                        break  # Assuming only one \"best score:\" line per file\n",
    "\n",
    "# Print results\n",
    "for jittering_val in sorted(jittering_scores):\n",
    "    scores = np.array(jittering_scores[jittering_val])\n",
    "    mean = np.mean(scores)\n",
    "    std = np.std(scores)\n",
    "    print(f\"Jittering {jittering_val}: Mean = {mean:.4f}, Std = {std:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
