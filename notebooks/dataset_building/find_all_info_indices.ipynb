{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to evaluate optional-input models, we need to find the molecules with all H, C, HSQC infomation, so the val/test set is the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, pathlib\n",
    "repo_path = pathlib.Path.cwd().parents[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nDo this because there are some files only have 1d nmr but no 2d nmr in the smiles dataset. \\nThis is because we have removed some duplicates in the smiles dataset.(during clean tautomer and weird-h-nmr)\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "Do this because there are some files only have 1d nmr but no 2d nmr in the smiles dataset. \n",
    "This is because we have removed some duplicates in the smiles dataset.(during clean tautomer and weird-h-nmr)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 106527.pt\n",
      "Removed 36854.pt\n",
      "Removed 100585.pt\n",
      "Removed 48903.pt\n",
      "Removed 105296.pt\n",
      "Removed 55091.pt\n",
      "Removed 40505.pt\n",
      "Removed 62753.pt\n",
      "Removed 103470.pt\n",
      "Removed 100582.pt\n",
      "Removed 12303.pt\n",
      "Removed 55867.pt\n",
      "Removed 107351.pt\n",
      "Removed 56156.pt\n",
      "Removed 76632.pt\n",
      "Removed 96197.pt\n",
      "Removed 36690.pt\n",
      "Removed 12354.pt\n",
      "Removed 6505.pt\n",
      "Removed 6937.pt\n",
      "Removed 6933.pt\n",
      "Removed 692.pt\n",
      "Removed 12367.pt\n",
      "Removed 4465.pt\n",
      "Removed 6932.pt\n",
      "Removed 12532.pt\n",
      "Removed 3934.pt\n",
      "Removed 6880.pt\n",
      "Removed 6868.pt\n",
      "Removed 12366.pt\n",
      "Removed 12538.pt\n",
      "Removed 12350.pt\n",
      "Removed 5613.pt\n",
      "Removed 7658.pt\n",
      "Removed 1523.pt\n",
      "Removed 12389.pt\n",
      "Removed 1755.pt\n",
      "Removed 6924.pt\n",
      "Removed 6939.pt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for split in ['train', 'val', 'test']:\n",
    "    all_file_candidates = os.listdir(f'/workspace/SMILES_dataset/{split}/oneD_NMR/')\n",
    "    \n",
    "    for file in all_file_candidates:\n",
    "        # if file doesn't exist\n",
    "        hsqc_file = f'/workspace/SMILES_dataset/{split}/HSQC/{file}'\n",
    "        if not os.path.exists(hsqc_file):\n",
    "            os.remove(f'/workspace/SMILES_dataset/{split}/oneD_NMR/{file}')\n",
    "            print(f\"Removed {file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43321 46224\n",
      "5336 5710\n",
      "5391 5717\n"
     ]
    }
   ],
   "source": [
    "import torch, pickle\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import os, tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "for split in ['train', 'val', 'test']:\n",
    "\n",
    "    all_file_candidates = os.listdir(f'/workspace/SMILES_dataset/{split}/oneD_NMR/')\n",
    "    file_with_all_NMRs = []\n",
    "    for file in all_file_candidates:\n",
    "        c_tensor, h_tensor = torch.load(f'/workspace/SMILES_dataset/{split}/oneD_NMR/{file}')\n",
    "        if len(c_tensor) > 0 and len(h_tensor) > 0:\n",
    "            file_with_all_NMRs.append(file)\n",
    "    print(len(file_with_all_NMRs), len(all_file_candidates))\n",
    "    save_path = f'{repo_path}/datasets/{split}_indices_of_full_info_NMRs.pkl'\n",
    "    with open(save_path, 'wb') as f:\n",
    "        pickle.dump(file_with_all_NMRs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
