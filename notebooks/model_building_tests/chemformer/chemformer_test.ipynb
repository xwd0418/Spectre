{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04/14/23\n",
    "\n",
    "This notebook is intended to test chemformer loading. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from models.chemformer.molbart import BARTModel\n",
    "from models.chemformer.tokeniser import MolEncTokeniser\n",
    "from models.chemformer.utils import REGEX, DEFAULT_MAX_SEQ_LEN\n",
    "from models.chemformer.molbart_dataset import Uspto50\n",
    "from models.chemformer.molbart_datamodule import FineTuneReactionDataModule\n",
    "from models.chemformer.decoder import DecodeSampler\n",
    "\n",
    "from models.ranked_transformer import Moonshot\n",
    "\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import TensorBoardLogger"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the model. Using code from the original chemformer repo (```molbart/util.py```)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocabulary\n",
    "from pathlib import Path\n",
    "vocab_path = \"tempdata/chemformer/bart_vocab.txt\"\n",
    "chem_token_start = 272\n",
    "tokeniser = MolEncTokeniser.from_vocab_file(\n",
    "  vocab_path, REGEX, chem_token_start\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uspto50 __init()__: \n",
      "[DS] <class 'pandas.core.frame.DataFrame'> 50037\n"
     ]
    }
   ],
   "source": [
    "# Dataset\n",
    "data_path = \"tempdata/chemformer/uspto_50.pickle\"\n",
    "aug_prob = 0.0\n",
    "dataset = Uspto50(\n",
    "  data_path, aug_prob, forward=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a batch size of 2.\n",
      "Building data module for forward prediction task...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Model\n",
    "model_type = \"bart\"\n",
    "uni_model = model_type == \"unified\"\n",
    "batch_size = 2\n",
    "train_tokens = None\n",
    "num_buckets = None\n",
    "\n",
    "dm = FineTuneReactionDataModule(\n",
    "    dataset,\n",
    "    tokeniser,\n",
    "    batch_size,\n",
    "    DEFAULT_MAX_SEQ_LEN,\n",
    "    forward_pred=True,\n",
    "    val_idxs=dataset.val_idxs,\n",
    "    test_idxs=dataset.test_idxs,\n",
    "    train_token_batch_size=train_tokens,\n",
    "    num_buckets=num_buckets,\n",
    "    unified_model=uni_model\n",
    ")\n",
    "sampler = DecodeSampler(tokeniser, DEFAULT_MAX_SEQ_LEN)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chemformer Hacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "model_path = \"tempdata/chemformer/model.ckpt\"\n",
    "obj = torch.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0847, -0.0391,  0.0424, -0.0030, -0.0634], device='cuda:0',\n",
       "       dtype=torch.float16)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj[\"state_dict\"][\"decoder.layers.1.norm1.bias\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.2.3 to v2.0.1.post0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file tempdata/chemformer/model.ckpt`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pushed an encoder with no defined bounds\n",
      "Pushed an encoder with no defined bounds\n",
      "Pushed an encoder with no defined bounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/pytorch_lightning/core/saving.py:153: UserWarning: Found keys that are in the model state dict but not in the checkpoint: ['latent', 'fc.weight', 'fc.bias', 'transformer_encoder.layers.0.self_attn.in_proj_weight', 'transformer_encoder.layers.0.self_attn.in_proj_bias', 'transformer_encoder.layers.0.self_attn.out_proj.weight', 'transformer_encoder.layers.0.self_attn.out_proj.bias', 'transformer_encoder.layers.0.linear1.weight', 'transformer_encoder.layers.0.linear1.bias', 'transformer_encoder.layers.0.linear2.weight', 'transformer_encoder.layers.0.linear2.bias', 'transformer_encoder.layers.0.norm1.weight', 'transformer_encoder.layers.0.norm1.bias', 'transformer_encoder.layers.0.norm2.weight', 'transformer_encoder.layers.0.norm2.bias', 'transformer_encoder.layers.1.self_attn.in_proj_weight', 'transformer_encoder.layers.1.self_attn.in_proj_bias', 'transformer_encoder.layers.1.self_attn.out_proj.weight', 'transformer_encoder.layers.1.self_attn.out_proj.bias', 'transformer_encoder.layers.1.linear1.weight', 'transformer_encoder.layers.1.linear1.bias', 'transformer_encoder.layers.1.linear2.weight', 'transformer_encoder.layers.1.linear2.bias', 'transformer_encoder.layers.1.norm1.weight', 'transformer_encoder.layers.1.norm1.bias', 'transformer_encoder.layers.1.norm2.weight', 'transformer_encoder.layers.1.norm2.bias', 'transformer_encoder.layers.2.self_attn.in_proj_weight', 'transformer_encoder.layers.2.self_attn.in_proj_bias', 'transformer_encoder.layers.2.self_attn.out_proj.weight', 'transformer_encoder.layers.2.self_attn.out_proj.bias', 'transformer_encoder.layers.2.linear1.weight', 'transformer_encoder.layers.2.linear1.bias', 'transformer_encoder.layers.2.linear2.weight', 'transformer_encoder.layers.2.linear2.bias', 'transformer_encoder.layers.2.norm1.weight', 'transformer_encoder.layers.2.norm1.bias', 'transformer_encoder.layers.2.norm2.weight', 'transformer_encoder.layers.2.norm2.bias', 'transformer_encoder.layers.3.self_attn.in_proj_weight', 'transformer_encoder.layers.3.self_attn.in_proj_bias', 'transformer_encoder.layers.3.self_attn.out_proj.weight', 'transformer_encoder.layers.3.self_attn.out_proj.bias', 'transformer_encoder.layers.3.linear1.weight', 'transformer_encoder.layers.3.linear1.bias', 'transformer_encoder.layers.3.linear2.weight', 'transformer_encoder.layers.3.linear2.bias', 'transformer_encoder.layers.3.norm1.weight', 'transformer_encoder.layers.3.norm1.bias', 'transformer_encoder.layers.3.norm2.weight', 'transformer_encoder.layers.3.norm2.bias', 'transformer_encoder.layers.4.self_attn.in_proj_weight', 'transformer_encoder.layers.4.self_attn.in_proj_bias', 'transformer_encoder.layers.4.self_attn.out_proj.weight', 'transformer_encoder.layers.4.self_attn.out_proj.bias', 'transformer_encoder.layers.4.linear1.weight', 'transformer_encoder.layers.4.linear1.bias', 'transformer_encoder.layers.4.linear2.weight', 'transformer_encoder.layers.4.linear2.bias', 'transformer_encoder.layers.4.norm1.weight', 'transformer_encoder.layers.4.norm1.bias', 'transformer_encoder.layers.4.norm2.weight', 'transformer_encoder.layers.4.norm2.bias', 'transformer_encoder.layers.5.self_attn.in_proj_weight', 'transformer_encoder.layers.5.self_attn.in_proj_bias', 'transformer_encoder.layers.5.self_attn.out_proj.weight', 'transformer_encoder.layers.5.self_attn.out_proj.bias', 'transformer_encoder.layers.5.linear1.weight', 'transformer_encoder.layers.5.linear1.bias', 'transformer_encoder.layers.5.linear2.weight', 'transformer_encoder.layers.5.linear2.bias', 'transformer_encoder.layers.5.norm1.weight', 'transformer_encoder.layers.5.norm1.bias', 'transformer_encoder.layers.5.norm2.weight', 'transformer_encoder.layers.5.norm2.bias', 'transformer_encoder.layers.6.self_attn.in_proj_weight', 'transformer_encoder.layers.6.self_attn.in_proj_bias', 'transformer_encoder.layers.6.self_attn.out_proj.weight', 'transformer_encoder.layers.6.self_attn.out_proj.bias', 'transformer_encoder.layers.6.linear1.weight', 'transformer_encoder.layers.6.linear1.bias', 'transformer_encoder.layers.6.linear2.weight', 'transformer_encoder.layers.6.linear2.bias', 'transformer_encoder.layers.6.norm1.weight', 'transformer_encoder.layers.6.norm1.bias', 'transformer_encoder.layers.6.norm2.weight', 'transformer_encoder.layers.6.norm2.bias', 'transformer_encoder.layers.7.self_attn.in_proj_weight', 'transformer_encoder.layers.7.self_attn.in_proj_bias', 'transformer_encoder.layers.7.self_attn.out_proj.weight', 'transformer_encoder.layers.7.self_attn.out_proj.bias', 'transformer_encoder.layers.7.linear1.weight', 'transformer_encoder.layers.7.linear1.bias', 'transformer_encoder.layers.7.linear2.weight', 'transformer_encoder.layers.7.linear2.bias', 'transformer_encoder.layers.7.norm1.weight', 'transformer_encoder.layers.7.norm1.bias', 'transformer_encoder.layers.7.norm2.weight', 'transformer_encoder.layers.7.norm2.bias']\n",
      "  rank_zero_warn(\n",
      "/opt/conda/lib/python3.10/site-packages/pytorch_lightning/core/saving.py:157: UserWarning: Found keys that are not in the model state dict but in the checkpoint: ['pos_emb', 'emb.weight', 'encoder.layers.0.self_attn.in_proj_weight', 'encoder.layers.0.self_attn.in_proj_bias', 'encoder.layers.0.self_attn.out_proj.weight', 'encoder.layers.0.self_attn.out_proj.bias', 'encoder.layers.0.linear1.weight', 'encoder.layers.0.linear1.bias', 'encoder.layers.0.linear2.weight', 'encoder.layers.0.linear2.bias', 'encoder.layers.0.norm1.weight', 'encoder.layers.0.norm1.bias', 'encoder.layers.0.norm2.weight', 'encoder.layers.0.norm2.bias', 'encoder.layers.1.self_attn.in_proj_weight', 'encoder.layers.1.self_attn.in_proj_bias', 'encoder.layers.1.self_attn.out_proj.weight', 'encoder.layers.1.self_attn.out_proj.bias', 'encoder.layers.1.linear1.weight', 'encoder.layers.1.linear1.bias', 'encoder.layers.1.linear2.weight', 'encoder.layers.1.linear2.bias', 'encoder.layers.1.norm1.weight', 'encoder.layers.1.norm1.bias', 'encoder.layers.1.norm2.weight', 'encoder.layers.1.norm2.bias', 'encoder.layers.2.self_attn.in_proj_weight', 'encoder.layers.2.self_attn.in_proj_bias', 'encoder.layers.2.self_attn.out_proj.weight', 'encoder.layers.2.self_attn.out_proj.bias', 'encoder.layers.2.linear1.weight', 'encoder.layers.2.linear1.bias', 'encoder.layers.2.linear2.weight', 'encoder.layers.2.linear2.bias', 'encoder.layers.2.norm1.weight', 'encoder.layers.2.norm1.bias', 'encoder.layers.2.norm2.weight', 'encoder.layers.2.norm2.bias', 'encoder.layers.3.self_attn.in_proj_weight', 'encoder.layers.3.self_attn.in_proj_bias', 'encoder.layers.3.self_attn.out_proj.weight', 'encoder.layers.3.self_attn.out_proj.bias', 'encoder.layers.3.linear1.weight', 'encoder.layers.3.linear1.bias', 'encoder.layers.3.linear2.weight', 'encoder.layers.3.linear2.bias', 'encoder.layers.3.norm1.weight', 'encoder.layers.3.norm1.bias', 'encoder.layers.3.norm2.weight', 'encoder.layers.3.norm2.bias', 'encoder.layers.4.self_attn.in_proj_weight', 'encoder.layers.4.self_attn.in_proj_bias', 'encoder.layers.4.self_attn.out_proj.weight', 'encoder.layers.4.self_attn.out_proj.bias', 'encoder.layers.4.linear1.weight', 'encoder.layers.4.linear1.bias', 'encoder.layers.4.linear2.weight', 'encoder.layers.4.linear2.bias', 'encoder.layers.4.norm1.weight', 'encoder.layers.4.norm1.bias', 'encoder.layers.4.norm2.weight', 'encoder.layers.4.norm2.bias', 'encoder.layers.5.self_attn.in_proj_weight', 'encoder.layers.5.self_attn.in_proj_bias', 'encoder.layers.5.self_attn.out_proj.weight', 'encoder.layers.5.self_attn.out_proj.bias', 'encoder.layers.5.linear1.weight', 'encoder.layers.5.linear1.bias', 'encoder.layers.5.linear2.weight', 'encoder.layers.5.linear2.bias', 'encoder.layers.5.norm1.weight', 'encoder.layers.5.norm1.bias', 'encoder.layers.5.norm2.weight', 'encoder.layers.5.norm2.bias', 'encoder.norm.weight', 'encoder.norm.bias']\n",
      "  rank_zero_warn(\n"
     ]
    }
   ],
   "source": [
    "model = Moonshot.load_from_checkpoint(\n",
    "  model_path, strict=False, module_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0847, -0.0391,  0.0424, -0.0030, -0.0634], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.decoder.layers[1].norm1.bias[:5]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuing the normal code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.2.3 to v2.0.1.post0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file tempdata/chemformer/model.ckpt`\n"
     ]
    }
   ],
   "source": [
    "DEFAULT_NUM_BEAMS = 10\n",
    "model_path = \"tempdata/chemformer/model.ckpt\"\n",
    "model = BARTModel.load_from_checkpoint(\n",
    "  model_path,\n",
    "  decode_sampler = sampler,\n",
    "  my_tokeniser = tokeniser,\n",
    ")\n",
    "model.cuda().eval()\n",
    "model.num_beams = DEFAULT_NUM_BEAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(limit_test_batches=1)` was configured so 1 batch will be used.\n"
     ]
    }
   ],
   "source": [
    "logger = TensorBoardLogger(\"tb_logs\", name=f\"eval_bart_uspto_50\")\n",
    "trainer = Trainer(\n",
    "    logger=logger,\n",
    "    limit_test_batches=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0:   0%|          | 0/1 [00:55<?, ?it/s]\n",
      "\n",
      "=== Describing forward input ===\n",
      "==> Key: encoder_input\n",
      "==> Value: <class 'torch.Tensor'>\n",
      "==> Size: torch.Size([38, 2]) torch.cuda.LongTensor torch.int64\n",
      "==> Decoded:  ['C1=COCCC1.COC(=O)CCC(=O)c1ccc(O)cc1O', 'COC(=O)c1cccc(C(=O)O)c1.Nc1cccnc1N']\n",
      "==> value\n",
      "\ttensor([[  2,   2],\n",
      "\t        [272, 272],\n",
      "\t        [274, 285],\n",
      "\t        [280, 272],\n",
      "\t        [272, 275]], device='cuda:0')\n",
      "==> Key: encoder_pad_mask\n",
      "==> Value: <class 'torch.Tensor'>\n",
      "==> Size: torch.Size([38, 2]) torch.cuda.BoolTensor torch.bool\n",
      "==> value\n",
      "\ttensor([[False, False],\n",
      "\t        [False, False],\n",
      "\t        [False, False],\n",
      "\t        [False, False],\n",
      "\t        [False, False]], device='cuda:0')\n",
      "==> Key: decoder_input\n",
      "==> Value: <class 'torch.Tensor'>\n",
      "==> Size: torch.Size([35, 2]) torch.cuda.LongTensor torch.int64\n",
      "==> Decoded:  ['COC(=O)CCC(=O)c1ccc(OC2CCCCO2)cc1O', 'COC(=O)c1cccc(-c2nc3cccnc3[nH]2)c1']\n",
      "==> value\n",
      "\ttensor([[  2,   2],\n",
      "\t        [272, 272],\n",
      "\t        [285, 285],\n",
      "\t        [272, 272],\n",
      "\t        [275, 275]], device='cuda:0')\n",
      "==> Key: decoder_pad_mask\n",
      "==> Value: <class 'torch.Tensor'>\n",
      "==> Size: torch.Size([35, 2]) torch.cuda.BoolTensor torch.bool\n",
      "==> value\n",
      "\ttensor([[False, False],\n",
      "\t        [False, False],\n",
      "\t        [False, False],\n",
      "\t        [False, False],\n",
      "\t        [False, False]], device='cuda:0')\n",
      "==> Key: target\n",
      "==> Value: <class 'torch.Tensor'>\n",
      "==> Size: torch.Size([35, 2]) torch.cuda.LongTensor torch.int64\n",
      "==> Decoded:  ['COC(=O)CCC(=O)c1ccc(OC2CCCCO2)cc1O', 'COC(=O)c1cccc(-c2nc3cccnc3[nH]2)c1']\n",
      "==> value\n",
      "\ttensor([[272, 272],\n",
      "\t        [285, 285],\n",
      "\t        [272, 272],\n",
      "\t        [275, 275],\n",
      "\t        [280, 280]], device='cuda:0')\n",
      "==> Key: target_mask\n",
      "==> Value: <class 'torch.Tensor'>\n",
      "==> Size: torch.Size([35, 2]) torch.cuda.BoolTensor torch.bool\n",
      "==> value\n",
      "\ttensor([[False, False],\n",
      "\t        [False, False],\n",
      "\t        [False, False],\n",
      "\t        [False, False],\n",
      "\t        [False, False]], device='cuda:0')\n",
      "==> Key: target_smiles\n",
      "==> Value: <class 'list'>\n",
      "=== Memory ===\n",
      "torch.Size([38, 2, 512])\n",
      "Test Step\n",
      "Target Smiles: \n",
      "['COC(=O)CCC(=O)c1ccc(OC2CCCCO2)cc1O', 'COC(=O)c1cccc(-c2nc3cccnc3[nH]2)c1']\n",
      "Mol_strs: \n",
      "[['C1=C(COC(=O)CCC(c2ccc(O)cc2O)=O)CCO1', 'c1(O)ccc(C(=O)CCC(=O)OCC2=COCC2)c(O)c1', 'C1=C(COC(=O)CCC(=O)c2ccc(O)cc2O)CCO1', 'C1=C(COC(=O)CCC(c2c(O)cc(O)cc2)=O)CCO1', 'C1(COC(=O)CCC(c2ccc(O)cc2O)=O)=COCC1', 'C1=C(COC(CCC(=O)c2ccc(O)cc2O)=O)CCO1', 'c1cc(O)cc(O)c1C(=O)CCC(=O)OCC1=COCC1', 'c1cc(O)cc(O)c1C(=O)CCC(OCC1=COCC1)=O', 'C1=C(COC(=O)CCC(=O)c2c(O)cc(O)cc2)CCO1', 'C1(COC(=O)CCC(=O)c2ccc(O)cc2O)=COCC1'], ['c1(Nc2cccnc2N)c(C(OC)=O)cccc1C(O)=O', 'c1(Nc2cccnc2N)c(C(OC)=O)cccc1C(=O)O', 'c1ccnc(N)c1Nc1c(C(OC)=O)cccc1C(O)=O', 'c1ccnc(N)c1Nc1c(C(=O)OC)cccc1C(O)=O', 'c1ccnc(N)c1Nc1c(C(OC)=O)cccc1C(=O)O', 'c1(Nc2cccnc2N)c(C(=O)OC)cccc1C(O)=O', 'c1ccnc(N)c1Nc1c(C(=O)OC)cccc1C(=O)O', 'c1(Nc2cccnc2N)c(C(=O)OC)cccc1C(=O)O', 'c1(C(O)=O)cccc(C(OC)=O)c1Nc1cccnc1N', 'c1(C(OC)=O)cccc(C(O)=O)c1Nc1cccnc1N']]\n",
      "Testing: 1it [00:04,  4.63s/it]\n",
      "Results for model: tempdata/chemformer/model.ckpt\n",
      "Item                     Result\n"
     ]
    }
   ],
   "source": [
    "results = trainer.test(model, datamodule=dm)\n",
    "def print_results(results):\n",
    "  print(f\"Results for model: {model_path}\")\n",
    "  print(f\"{'Item':<25}Result\")\n",
    "  for key, val in results.items():\n",
    "    print(f\"{key:<25} {val:.4f}\")\n",
    "print_results(results[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
