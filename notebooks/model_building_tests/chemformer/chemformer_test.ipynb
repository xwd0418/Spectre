{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04/14/23\n",
    "\n",
    "This notebook is intended to test chemformer loading. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from models.chemformer.molbart import BARTModel\n",
    "from models.chemformer.tokeniser import MolEncTokeniser\n",
    "from models.chemformer.utils import REGEX, DEFAULT_MAX_SEQ_LEN\n",
    "from models.chemformer.molbart_dataset import Uspto50\n",
    "from models.chemformer.molbart_datamodule import FineTuneReactionDataModule\n",
    "from models.chemformer.decoder import DecodeSampler\n",
    "\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import TensorBoardLogger"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the model. Using code from the original chemformer repo (```molbart/util.py```)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_NUM_BEAMS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a batch size of 8.\n",
      "Building data module for forward prediction task...\n"
     ]
    }
   ],
   "source": [
    "vocab_path = \"tempdata/chemformer/bart_vocab.txt\"\n",
    "chem_token_start = 272\n",
    "tokeniser = MolEncTokeniser.from_vocab_file(\n",
    "  vocab_path, REGEX, chem_token_start\n",
    ")\n",
    "\n",
    "data_path = \"tempdata/chemformer/uspto_50.pickle\"\n",
    "aug_prob = 0.0\n",
    "dataset = Uspto50(\n",
    "  data_path, aug_prob, forward=True\n",
    ")\n",
    "\n",
    "model_type = \"bart\"\n",
    "uni_model = model_type == \"unified\"\n",
    "batch_size = 8\n",
    "train_tokens = None\n",
    "num_buckets = None\n",
    "\n",
    "dm = FineTuneReactionDataModule(\n",
    "    dataset,\n",
    "    tokeniser,\n",
    "    batch_size,\n",
    "    DEFAULT_MAX_SEQ_LEN,\n",
    "    forward_pred=True,\n",
    "    val_idxs=dataset.val_idxs,\n",
    "    test_idxs=dataset.test_idxs,\n",
    "    train_token_batch_size=train_tokens,\n",
    "    num_buckets=num_buckets,\n",
    "    unified_model=uni_model\n",
    ")\n",
    "\n",
    "sampler = DecodeSampler(tokeniser, DEFAULT_MAX_SEQ_LEN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"tempdata/chemformer/model.ckpt\"\n",
    "model = BARTModel.load_from_checkpoint(\n",
    "  model_path,\n",
    "  decode_sampler = sampler\n",
    ")\n",
    "model.cuda().eval()\n",
    "model.num_beams = DEFAULT_NUM_BEAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/loops/utilities.py:91: PossibleUserWarning: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n",
      "  rank_zero_warn(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(limit_test_batches=1)` was configured so 1 batch will be used.\n"
     ]
    }
   ],
   "source": [
    "logger = TensorBoardLogger(\"tb_logs\", name=f\"eval_bart_uspto_50\")\n",
    "trainer = Trainer(\n",
    "    logger=logger,\n",
    "    limit_test_batches=1,\n",
    "    gpus=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]Test Step\n",
      "Target Smiles: \n",
      "['COC(=O)CCC(=O)c1ccc(OC2CCCCO2)cc1O', 'COC(=O)c1cccc(-c2nc3cccnc3[nH]2)c1', 'CON(C)C(=O)C1CCC(NC(=O)OC(C)(C)C)CC1', 'O=[N+]([O-])c1ccc(Cl)nc1Nc1ccc(O)cc1', 'NCC1=CC[C@@H](c2ccc(Cl)cc2Cl)[C@H]([N+](=O)[O-])C1', 'CCc1oc(-c2ccc(C(F)(F)F)cc2)nc1COC[C@@H]1CCC[C@H](COC(C)(C)C(=O)O)C1', 'Cc1noc(C)c1NC(=O)Nc1ccc2nc(N[C@@H]3CCc4ccccc43)ccc2c1', 'Cc1cnc(N2CCN(C(=O)c3ccc(N4CCCS4(=O)=O)nc3C)CC2)c(C)c1']\n",
      "Mol_strs: \n",
      "[['C1=C(COC(=O)CCC(c2ccc(O)cc2O)=O)CCO1', 'c1(O)ccc(C(=O)CCC(=O)OCC2=COCC2)c(O)c1', 'C1=C(COC(=O)CCC(=O)c2ccc(O)cc2O)CCO1', 'C1=C(COC(=O)CCC(c2c(O)cc(O)cc2)=O)CCO1', 'C1(COC(=O)CCC(c2ccc(O)cc2O)=O)=COCC1', 'C1=C(COC(CCC(=O)c2ccc(O)cc2O)=O)CCO1', 'c1cc(O)cc(O)c1C(=O)CCC(=O)OCC1=COCC1', 'c1cc(O)cc(O)c1C(=O)CCC(OCC1=COCC1)=O', 'C1=C(COC(=O)CCC(=O)c2c(O)cc(O)cc2)CCO1', 'C1(COC(=O)CCC(=O)c2ccc(O)cc2O)=COCC1'], ['c1(Nc2cccnc2N)c(C(OC)=O)cccc1C(O)=O', 'c1(Nc2cccnc2N)c(C(OC)=O)cccc1C(=O)O', 'c1ccnc(N)c1Nc1c(C(OC)=O)cccc1C(O)=O', 'c1ccnc(N)c1Nc1c(C(=O)OC)cccc1C(O)=O', 'c1ccnc(N)c1Nc1c(C(OC)=O)cccc1C(=O)O', 'c1(Nc2cccnc2N)c(C(=O)OC)cccc1C(O)=O', 'c1ccnc(N)c1Nc1c(C(=O)OC)cccc1C(=O)O', 'c1(Nc2cccnc2N)c(C(=O)OC)cccc1C(=O)O', 'c1(C(O)=O)cccc(C(OC)=O)c1Nc1cccnc1N', 'c1(C(OC)=O)cccc(C(O)=O)c1Nc1cccnc1N'], ['CC(C)(C)OC(=O)NC1CCC(C(=O)O)CC1CNOC', 'C1C(C(=O)O)CCC(NC(=O)OC(C)(C)C)C1CNOC', 'C1C(C(=O)O)CCC(NC(OC(C)(C)C)=O)C1CNOC', 'CC(C)(C)OC(=O)NC1CCC(C(O)=O)CC1CNOC', 'C1C(C(O)=O)CCC(NC(=O)OC(C)(C)C)C1CNOC', 'C1C(C(O)=O)CCC(NC(OC(C)(C)C)=O)C1CNOC', 'CC(C)(C)OC(NC1CCC(C(=O)O)CC1)=O', 'CC(C)(OC(=O)NC1CCC(C(=O)O)CC1)C', 'C1CC(C(=O)O)CC(CNOC)C1NC(OC(C)(C)C)=O', 'CC(OC(=O)NC1CCC(C(=O)O)CC1)(C)C'], ['c1cc(Cl)nc(Cl)c1[N+](=O)[O-]', 'Clc1nc(Cl)ccc1[N+](=O)[O-]', 'c1(Cl)nc(Cl)ccc1[N+](=O)[O-]', 'c1cc(Cl)nc(Cl)c1[N+]([O-])=O', 'c1c(O)ccc(N)c1O=[N+](c1c(Cl)nc(Cl)cc1)[O-]', 'c1c(O)ccc(N)c1O=[N+](c1ccc(Cl)nc1Cl)[O-]', 'c1(O)ccc(N)c(O=[N+](c2c(Cl)nc(Cl)cc2)[O-])c1', 'c1(O)ccc(N)c(O=[N+]([O-])c2c(Cl)nc(Cl)cc2)c1', 'c1c(O)ccc(N)c1O=[N+]([O-])c1c(Cl)nc(Cl)cc1', 'c1(Cl)nc(Cl)c([N+](=O)[O-])cc1[N+](=O)[O-]'], ['C1(CN=[N+]=[N-])=CC[C@@H](c2ccc(Cl)cc2Cl)[C@H]([N+]([O-])=O)C1', 'C1(CN=[N+]=[N-])=CC[C@@H](c2c(Cl)cc(Cl)cc2)[C@H]([N+]([O-])=O)C1', 'C1(CN=[N+]=[N-])=CC[C@@H](c2ccc(Cl)cc2Cl)[C@H]([N+](=O)[O-])C1', 'C1(CN=[N+]=[N-])=CC[C@@H](c2c(Cl)cc(Cl)cc2)[C@H]([N+](=O)[O-])C1', '[C@H]1([N+]([O-])=O)[C@H](c2ccc(Cl)cc2Cl)CC=C(CN=[N+]=[N-])C1', '[O-][N+](=O)[C@@H]1CC(CN=[N+]=[N-])=CC[C@H]1c1ccc(Cl)cc1Cl', 'c1cc(Cl)cc(Cl)c1[C@@H]1CC=C(CN=[N+]=[N-])C[C@H]1[N+]([O-])=O', 'c1(Cl)ccc([C@@H]2CC=C(CN=[N+]=[N-])C[C@H]2[N+]([O-])=O)c(Cl)c1', 'c1cc(Cl)cc(Cl)c1[C@H]1[C@H]([N+]([O-])=O)CC(CN=[N+]=[N-])=CC1', 'Clc1cc(Cl)ccc1[C@@H]1CC=C(CN=[N+]=[N-])C[C@H]1[N+]([O-])=O'], ['FC(F)(F)c1ccc(-c2oc(CC)c(COC[C@@H]3CCC[C@H](COC(C(OC(C)(C)C)=O)(C)C)O3)n2)cc1', 'c1(-c2ccc(C(F)(F)F)cc2)oc(CC)c(COC[C@@H]2CCC[C@H](COC(C(OC(C)(C)C)=O)(C)C)O2)n1', 'c1cc(C(F)(F)F)ccc1-c1oc(CC)c(COC[C@@H]2CCC[C@H](COC(C(OC(C)(C)C)=O)(C)C)O2)n1', 'c1(-c2ccc(C(F)(F)F)cc2)oc(CC)c(COC[C@H]2C[C@@H](COC(C(OC(C)(C)C)=O)(C)C)CCC2)n1', 'FC(F)(F)c1ccc(-c2oc(CC)c(COC[C@@H]3CCC[C@H](COC(C)(C)C(OC(C)(C)C)=O)O3)n2)cc1', 'c1(-c2ccc(C(F)(F)F)cc2)nc(COC[C@@H]2CCC[C@H](COC(C)(C)C(OC(C)(C)C)=O)O2)c(CC)o1', 'c1(-c2ccc(C(F)(F)F)cc2)oc(CC)c(COC[C@@H]2CCC[C@H](COC(C)(C)C(OC(C)(C)C)=O)O2)n1', 'c1cc(C(F)(F)F)ccc1-c1oc(CC)c(COC[C@@H]2CCC[C@H](COC(C)(C)C(OC(C)(C)C)=O)O2)n1', 'c1(-c2ccc(C(F)(F)F)cc2)oc(CC)c(COC[C@@H]2CCC[C@H](COC(C)(C)C(=O)OC(C)(C)C)O2)n1', 'c1(-c2ccc(C(F)(F)F)cc2)oc(CC)c(COC[C@@H]2CCC[C@H](COC(C)(C(OC(C)(C)C)=O)C)O2)n1'], ['O=C=Nc1c(C)noc1C', 'O=C=Nc1c(C)onc1C', 'c1(C)c(N=C=O)c(C)on1', 'c1(N[C@@H]2CCc3ccccc32)nc2ccc(N=C=O)cc2cc1', 'c1(N[C@@H]2CCc3ccccc32)ccc2cc(N=C=O)ccc2n1', 'c1(N[C@@H]2CCc3ccccc32)ccc2c(ccc(N=C=O)c2)n1', 'c1ccc2c(c1)CC[C@H]2Nc1ccc2c(ccc(N=C=O)c2)n1', 'c1(N[C@@H]2CCc3ccccc32)nc2ccc(NO=C=Nc3c(C)noc3C)cc2cc1', 'c1(C)c(N=C=O)c(Nc2cc3ccc(N[C@@H]4CCc5ccccc54)nc3cc2)c(C)on1', 'c1(C)c(N=C=O)c(Nc2cc3ccc(N[C@@H]4CCc5ccccc54)nc3cc2)c(C)no1'], ['c1(C)c(N2CCNCC2)ncc(COCc2c(C(=O)OC)ccc(N3S(=O)(=O)CCC3)n2)c1', 'c1(C)c(N2CCNCC2)ncc(COCc2c(C(OC)=O)ccc(N3S(=O)(=O)CCC3)n2)c1', 'O=S1(=O)N(c2nc(COCc3cnc(N4CCNCC4)c(C)c3)c(C(=O)OC)cc2)CCC1', 'O=S1(=O)N(c2nc(COCc3cnc(N4CCNCC4)c(C)c3)c(C(OC)=O)cc2)CCC1', 'c1(C)c(N2CCNCC2)ncc(COCc2nc(N3S(=O)(=O)CCC3)ccc2C(=O)OC)c1', 'c1(C)c(N2CCNCC2)ncc(COCc2nc(N3S(=O)(=O)CCC3)ccc2C(OC)=O)c1', 'c1(C)c(N2CCNCC2)ncc(COCc2nc(N3CCCS3(=O)=O)ccc2C(=O)OC)c1', 'c1(C)c(N2CCNCC2)ncc(COCc2c(C(=O)OC)ccc(N3CCCS3(=O)=O)n2)c1', 'c1(C)c(N2CCNCC2)ncc(COCc2nc(N3CCCS3(=O)=O)ccc2C(OC)=O)c1', 'O=S1(=O)CCCN1c1nc(COCc2cnc(N3CCNCC3)c(C)c2)c(C(OC)=O)cc1']]\n",
      "Testing DataLoader 0: 100%|██████████| 1/1 [00:19<00:00, 19.05s/it]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "         Test metric                   DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     test_invalid_smiles                   0.0\n",
      "          test_loss                 0.7543028593063354\n",
      "   test_molecular_accuracy                 0.0\n",
      "test_molecular_top_10_accuracy             0.0\n",
      "test_molecular_top_1_accuracy              0.0\n",
      "test_molecular_top_2_accuracy              0.0\n",
      "test_molecular_top_3_accuracy              0.0\n",
      "test_molecular_top_5_accuracy              0.0\n",
      "       test_perplexity                     0.0\n",
      "        test_token_acc              0.8303030133247375\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Results for model: tempdata/chemformer/model.ckpt\n",
      "Item                     Result\n",
      "test_loss                 0.7543\n",
      "test_token_acc            0.8303\n",
      "test_perplexity           0.0000\n",
      "test_invalid_smiles       0.0000\n",
      "test_molecular_accuracy   0.0000\n",
      "test_molecular_top_1_accuracy 0.0000\n",
      "test_molecular_top_2_accuracy 0.0000\n",
      "test_molecular_top_3_accuracy 0.0000\n",
      "test_molecular_top_5_accuracy 0.0000\n",
      "test_molecular_top_10_accuracy 0.0000\n"
     ]
    }
   ],
   "source": [
    "results = trainer.test(model, datamodule=dm)\n",
    "def print_results(results):\n",
    "  print(f\"Results for model: {model_path}\")\n",
    "  print(f\"{'Item':<25}Result\")\n",
    "  for key, val in results.items():\n",
    "    print(f\"{key:<25} {val:.4f}\")\n",
    "print_results(results[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
