{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# for radius up to 4, calculate the entropy for each frags\n",
    "\n",
    "1. load count and each frags and compute the entropy\n",
    "2. sort the entropy and remember the topk index (k=6144)\n",
    "3. remap the high-entropy frags to the some new index\n",
    "4. save the re-mapping \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import rdMolDescriptors\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import Draw\n",
    "import pathlib, pickle, os, tqdm\n",
    "import torch\n",
    "import multiprocessing, collections\n",
    "\n",
    "from collections import defaultdict  \n",
    "\n",
    "RADIUS_UPPER_LIMIT = 4\n",
    "DATASET_root_path = pathlib.Path(\"/workspace/\")\n",
    "DATASETS = [\"OneD_Only_Dataset\", \"SMILES_dataset\"]\n",
    "DATASET_INDEX_SOURCE = [\"oneD_NMR\" , \"HSQC\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. load count and each frags and compute the entropy\n",
    "save_path = DATASET_root_path / f\"count_fragments_radius_under_{RADIUS_UPPER_LIMIT}.pkl\"\n",
    "with open(save_path, \"rb\") as f:\n",
    "    frags_count = pickle.load(f)\n",
    "    \n",
    "    \n",
    "def compute_entropy(data, use_natural_log=False):\n",
    "    probability = data/(total_size)\n",
    "    if use_natural_log:\n",
    "        entropy = (probability * np.log(np.clip(probability,1e-7 ,1)) )\n",
    "    else:\n",
    "        entropy = (probability * np.log2(np.clip(probability,1e-7 ,1)) )\n",
    "    return entropy\n",
    "\n",
    "def keep_smallest_entropy(data, size=6144,  use_natural_log=False):\n",
    "    entropy = compute_entropy(data, use_natural_log)\n",
    "    indices_of_min_6144 = np.argsort(entropy)[:size]\n",
    "    # print(entropy, indices_of_min_6144)\n",
    "    total_entropy = entropy[indices_of_min_6144].sum()\n",
    "    return total_entropy, indices_of_min_6144\n",
    "\n",
    "\n",
    "frags_count.items()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
