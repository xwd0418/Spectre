{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "choosing Morgan_FP_loader\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, message=\"You are using `torch.load` with `weights_only=False`\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"The PyTorch API of nested tensors is in prototype stage and will change in the near future.\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys, os\n",
    "sys.path.insert(0,\"/root/gurusmart/MorganFP_prediction/reproduce_previous_works/Spectre\")\n",
    "            \n",
    "import torch\n",
    "torch.set_printoptions(precision=10)\n",
    "\n",
    "\n",
    "import yaml\n",
    "torch.set_float32_matmul_precision('high')\n",
    "from pathlib import Path\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "# load model \n",
    "from datasets.dataset_utils import  fp_loader_configer\n",
    "\n",
    "fp_loader_configer.select_version(\"Morgan_FP\")\n",
    "fp_loader = fp_loader_configer.fp_loader\n",
    "\n",
    "import numpy as np \n",
    "import random\n",
    "seed=2\n",
    "torch.cuda.manual_seed_all(seed) \n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "526316\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open(f'/root/gurusmart/MorganFP_prediction/inference_data/coconut_loutus_hyun_training/inference_metadata_latest_RDkit.pkl', 'rb') as file:\n",
    "    smiles_and_names = pickle.load(file)\n",
    "print(len(smiles_and_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.optional_input_ranked_transformer import OptionalInputRankedTransformer\n",
    "from datasets.optional_2d_folder_dataset import OptionalInputDataModule\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "loader_idx_to_name_mapping = {\n",
    "    0: \"eHSQC, H NMR, and C NMR\",\n",
    "    1: \"eHSQC and H NMR\",\n",
    "    2: \"eHSQC and C NMR\",\n",
    "    3: \"eHSQC Only\",\n",
    "    4: \"C NMR and H NMR\",\n",
    "    5: \"H NMR Only\",\n",
    "    6: \"C NMR Only\",\n",
    "    7: \"Normal HSQC only\",\n",
    "    8: \"standard HSQC, H NMR, and C NMR\",\n",
    "    9: \"standard HSQC and H NMR\",\n",
    "    10: \"standard HSQC and C NMR\",\n",
    "    \n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/torch/_utils.py:315: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ../aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "  result = torch.sparse_compressed_tensor(\n"
     ]
    }
   ],
   "source": [
    "max_radius = 6\n",
    "fp_dim = 16384\n",
    "rankingset_path = f\"/root/gurusmart/MorganFP_prediction/inference_data/inference_rankingset_with_stable_sort/vanilla_fp_rankingset_max_radius_{max_radius}_fp_dim_{fp_dim}_stacked_together_sparse/FP.pt\"\n",
    "\n",
    "rankingset_data = torch.load(rankingset_path).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_extra_input_types(checkpoint_path):\n",
    "    # checkpoint_path = \"/root/gurusmart/MorganFP_prediction/reproduce_previous_works/entropy_on_hashes/flexible_models_jittering_flexible_MW_flexible_normal_hsqc/r0_r6_trial_1/checkpoints/epoch=95-step=21696.ckpt\"\n",
    "    checkpoint_path = Path(checkpoint_path)\n",
    "    model_path = checkpoint_path.parents[1]\n",
    "    hyperpaerameters_path = model_path / \"hparams.yaml\"\n",
    "\n",
    "    with open(hyperpaerameters_path, 'r') as file:\n",
    "        hparams = yaml.safe_load(file)\n",
    "        \n",
    "    del hparams['checkpoint_path'] # prevent double defition of checkpoint_path\n",
    "\n",
    "    fp_loader = fp_loader_configer.fp_loader\n",
    "    hparams['num_workers'] = 0\n",
    "    model = OptionalInputRankedTransformer.load_from_checkpoint(checkpoint_path, fp_loader = fp_loader,  **hparams)\n",
    "    max_radius = int(hparams['FP_choice'].split(\"_\")[-1])\n",
    "    fp_loader.setup(hparams['out_dim'], max_radius)\n",
    "\n",
    "    datamodule = OptionalInputDataModule(dir=\"/workspace/SMILES_dataset\", FP_choice=hparams[\"FP_choice\"], input_src=[\"HSQC\", \"oneD_NMR\"], fp_loader = fp_loader_configer.fp_loader, batch_size=1, parser_args=hparams)\n",
    "    datamodule.setup(\"test\")\n",
    "    # loader_all_inputs, loader_HSQC_H_NMR, loader_HSQC_C_NMR, loader_only_hsqc, loader_only_1d, loader_only_H_NMR, loader_only_C_NMR = datamodule.test_dataloader()\n",
    "    test_dataloaders = datamodule.test_dataloader()\n",
    "\n",
    "    import tqdm\n",
    "    model.setup_ranker()\n",
    "    model.ranker.data = model.ranker.data.to(model.device)\n",
    "    \n",
    "\n",
    "    from collections import defaultdict\n",
    "\n",
    "    ## with MW\n",
    "    mean_rank_records = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "    for i in range(11):\n",
    "        if i<7:\n",
    "            continue\n",
    "        loader_idx = i\n",
    "        if i == 7: # standard HSQC only\n",
    "            loader_idx = 3\n",
    "        if i == 8: # standard HSQC, H NMR, and C NMR\n",
    "            loader_idx = 0\n",
    "        if i == 9: # standard HSQC and H NMR\n",
    "            loader_idx = 1\n",
    "        if i == 10: # standard HSQC and C NMR\n",
    "            loader_idx = 2\n",
    "            \n",
    "        for idx, batch in tqdm.tqdm(enumerate(test_dataloaders[loader_idx])):\n",
    "            batch[0] = batch[0].to(model.device)\n",
    "            batch[1] = batch[1].to(model.device)\n",
    "            batch[2] = batch[2].to(model.device)\n",
    "            \n",
    "            if i >= 7:\n",
    "                # last column all zeros\n",
    "                batch[0][:, :, -1] = 0\n",
    "            with torch.no_grad():\n",
    "                result =  model.test_step(batch, 0, dataloader_idx=loader_idx)\n",
    "            for k,v in result.items():\n",
    "                \n",
    "                mean_rank_records[loader_idx_to_name_mapping[i]][k].append(v)\n",
    "                \n",
    "                \n",
    "    for k,v in mean_rank_records.items():\n",
    "        for k2, v2 in v.items():\n",
    "            mean_rank_records[k][k2] = np.mean(v2)\n",
    "            \n",
    "    return mean_rank_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialized SignCoordinateEncoder[784] with dims [365, 365, 54] and 2 positional encoders. 54 bits are reserved for encoding the final bit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HsqcRankedTransformer saving args\n",
      "loading /root/gurusmart/MorganFP_prediction/inference_data/inference_rankingset_with_stable_sort/vanilla_fp_rankingset_max_radius_6_fp_dim_16384_stacked_together_sparse/FP.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4056it [01:37, 41.79it/s]\n",
      "4056it [01:28, 45.66it/s]\n",
      "4056it [01:23, 48.44it/s]\n",
      "4056it [01:37, 41.58it/s]\n",
      "Initialized SignCoordinateEncoder[784] with dims [365, 365, 54] and 2 positional encoders. 54 bits are reserved for encoding the final bit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HsqcRankedTransformer saving args\n",
      "Morgan_FP_loader is already setup\n",
      "loading /root/gurusmart/MorganFP_prediction/inference_data/inference_rankingset_with_stable_sort/vanilla_fp_rankingset_max_radius_6_fp_dim_16384_stacked_together_sparse/FP.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4056it [01:25, 47.42it/s]\n",
      "4056it [01:38, 41.35it/s]\n",
      "4056it [01:38, 41.25it/s]\n",
      "4056it [01:38, 41.26it/s]\n",
      "Initialized SignCoordinateEncoder[784] with dims [365, 365, 54] and 2 positional encoders. 54 bits are reserved for encoding the final bit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HsqcRankedTransformer saving args\n",
      "Morgan_FP_loader is already setup\n",
      "loading /root/gurusmart/MorganFP_prediction/inference_data/inference_rankingset_with_stable_sort/vanilla_fp_rankingset_max_radius_6_fp_dim_16384_stacked_together_sparse/FP.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4056it [01:22, 49.32it/s]\n",
      "4056it [01:22, 48.97it/s]\n",
      "4056it [01:22, 48.87it/s]\n",
      "4056it [01:22, 48.88it/s]\n"
     ]
    }
   ],
   "source": [
    "three_model_mean_rank_records = []\n",
    "for path in [\n",
    "    \"/root/gurusmart/MorganFP_prediction/reproduce_previous_works/entropy_on_hashes/flexible_models_jittering_flexible_MW_flexible_normal_hsqc/r6_16384_trial_1/checkpoints/epoch=75-step=51528.ckpt\",\n",
    "    \"/root/gurusmart/MorganFP_prediction/reproduce_previous_works/entropy_on_hashes/flexible_models_jittering_flexible_MW_flexible_normal_hsqc/r6_16384_trial_2/checkpoints/epoch=75-step=51528.ckpt\",\n",
    "    \"/root/gurusmart/MorganFP_prediction/reproduce_previous_works/entropy_on_hashes/flexible_models_jittering_flexible_MW_flexible_normal_hsqc/r6_16384_trial_3/checkpoints/epoch=71-step=48816.ckpt\"\n",
    "]:\n",
    "    mean_rank_records = test_extra_input_types(path)\n",
    "    three_model_mean_rank_records.append(mean_rank_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Normal HSQC only\n",
      "  mean_rank: 1137.2358 ± 26.2340\n",
      "  rank_1: 0.2341 ± 0.0030\n",
      "  rank_5: 0.5708 ± 0.0047\n",
      "  rank_10: 0.6852 ± 0.0024\n",
      "\n",
      "standard HSQC, H NMR, and C NMR\n",
      "  mean_rank: 545.9248 ± 60.8683\n",
      "  rank_1: 0.2631 ± 0.0021\n",
      "  rank_5: 0.6251 ± 0.0045\n",
      "  rank_10: 0.7447 ± 0.0083\n",
      "\n",
      "standard HSQC and H NMR\n",
      "  mean_rank: 862.5087 ± 118.3739\n",
      "  rank_1: 0.2449 ± 0.0044\n",
      "  rank_5: 0.5894 ± 0.0014\n",
      "  rank_10: 0.7066 ± 0.0046\n",
      "\n",
      "standard HSQC and C NMR\n",
      "  mean_rank: 474.9915 ± 86.3026\n",
      "  rank_1: 0.2650 ± 0.0033\n",
      "  rank_5: 0.6248 ± 0.0047\n",
      "  rank_10: 0.7391 ± 0.0051\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "# Assume your data is stored in three_model_mean_rank_records\n",
    "# Initialize final result dictionary\n",
    "average_metrics = defaultdict(dict)\n",
    "\n",
    "# Get all dataset names (e.g., 'standard HSQC, H NMR, and C NMR', etc.)\n",
    "dataset_names = three_model_mean_rank_records[0].keys()\n",
    "\n",
    "for dataset in dataset_names:\n",
    "    # For each metric under this dataset\n",
    "    metrics = three_model_mean_rank_records[0][dataset].keys()\n",
    "    \n",
    "    for metric in metrics:\n",
    "        # Collect metric value from all 3 models\n",
    "        values = [model[dataset][metric] for model in three_model_mean_rank_records]\n",
    "        average_metrics[dataset][metric] = (float(np.mean(values)), float(np.std(values)))\n",
    "\n",
    "# Print or use `average_metrics` as needed\n",
    "for dataset, metrics in average_metrics.items():\n",
    "    print(f\"\\n{dataset}\")\n",
    "    for metric_name, avg_val in metrics.items():\n",
    "        if \"rank\" in metric_name:\n",
    "            print(f\"  {metric_name}: {avg_val[0]:.4f} ± {avg_val[1]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"/root/gurusmart/MorganFP_prediction/reproduce_previous_works/Spectre/inference/flexible_models_avg_by_3_16384.pkl\"\n",
    "import pickle\n",
    "with open(save_path, 'wb') as f:\n",
    "    pickle.dump(average_metrics, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
